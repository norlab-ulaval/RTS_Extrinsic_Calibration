{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff877c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from rosbags.typesys import get_types_from_msg, register_types\n",
    "\n",
    "\n",
    "def guess_msgtype(path: Path) -> str:\n",
    "    \"\"\"Guess message type name from path.\"\"\"\n",
    "    name = path.relative_to(path.parents[2]).with_suffix('')\n",
    "    if 'msg' not in name.parts:\n",
    "        name = name.parent / 'msg' / name.name\n",
    "    return str(name)\n",
    "\n",
    "\n",
    "add_types = {}\n",
    "\n",
    "for pathstr in [\n",
    "    '/home/william/ros2_ws/src/theodolite_node_msgs/msg/TheodoliteCoordsStamped.msg',\n",
    "]:\n",
    "    msgpath = Path(pathstr)\n",
    "    msgdef = msgpath.read_text(encoding='utf-8')\n",
    "    add_types.update(get_types_from_msg(msgdef, guess_msgtype(msgpath)))\n",
    "\n",
    "register_types(add_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83134f9a-9db2-4600-a9e2-cb67d376842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import animation\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import importlib\n",
    "import scripts.theodolite_function as tfu\n",
    "import scripts.theodolite_utils as ttf\n",
    "# import GPy\n",
    "import scripts.gp_prediction_utils as GPf\n",
    "tfu = importlib.reload(tfu)\n",
    "ttf = importlib.reload(ttf)\n",
    "GPf = importlib.reload(GPf)\n",
    "\n",
    "from scipy.interpolate import splprep, splev\n",
    "from scipy import interpolate\n",
    "from scipy import spatial\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from IPython.display import HTML\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct, ConstantKernel)\n",
    "from stheno import B, Measure, GP, EQ, Delta\n",
    "import torch\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from wbml.plot import tweak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e2fb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read rosbag of grand axe and show the trajectory\n",
    "ttf = importlib.reload(ttf)\n",
    "tfu = importlib.reload(tfu)\n",
    "GPf = importlib.reload(GPf)\n",
    "\n",
    "'''\n",
    "file = [\"/media/will/T7/theodolite_bags/20220715_TS/2022-07-15-11-50-15.bag\",\n",
    "        \"/media/will/T7/theodolite_bags/20220715_TS/2022-07-15-11-53-12.bag\",\n",
    "        \"/media/will/T7/theodolite_bags/20220715_TS/2022-07-15-11-58-58.bag\",\n",
    "        \"/media/will/T7/theodolite_bags/20220715_TS/2022-07-15-14-42-27.bag\"]\n",
    "        # \"/media/will/T7/theodolite_bags/20220513_TS_2/2022-05-13-22-35-30.bag\",\n",
    "        # \"/media/will/T7/theodolite_bags/20220513_TS_2/2022-05-13-22-51-40.bag\"]\n",
    "\n",
    "output = [\"TS/20220717/01/\",\n",
    "          \"TS/20220717/02/\",\n",
    "          \"TS/20220717/03/\",\n",
    "          \"TS/20220717/04/\",\n",
    "          \"TS/20220717/05/\"]\n",
    "          # \"TS/20220513/06/\"]  \n",
    "'''\n",
    "\n",
    "file = [\n",
    "        # \"/media/william/T7/theodolite_bags/20220224_TS/2022-02-24-15-34-38.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220307_TS/2022-03-07-19-20-06.bag\",\n",
    "# #         \"/home/norlab/Data/IROS_2022/20220312_TS/2022-03-12-09-45-12.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220314_TS/2022-03-14-10-47-49.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220316_TS/2022-03-16-19-02-42.bag\",\n",
    "        \"/media/william/T7/theodolite_bags/20220331_TS/2022-03-31-10-22-52.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220331_TS/2022-03-31-11-20-05.bag\",\n",
    "# #         \"/home/norlab/Data/IROS_2022/20220427_TS/2022-04-27-12-12-10_filered.bag\",\n",
    "        \"/media/william/T7/theodolite_bags/20220505_TS/empty1_2022-05-05-19-14-33.bag\",\n",
    "        \"/media/william/T7/theodolite_bags/20220505_TS/cones1_2022-05-05-19-25-54.bag\",\n",
    "#         \"/media/william/T7/theodolite_bags/20220513_TS/2022-05-13-10-30-37_filtered.bag\",\n",
    "#         \"/media/william/T7/theodolite_bags/20220513_TS/2022-05-13-11-01-56.bag\",\n",
    "#         \"/media/william/T7/theodolite_bags/20220513_TS/2022-05-13-11-24-28.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220513_TS_2/2022-05-13-21-49-12_filtered.bag\",\n",
    "# #         \"/home/norlab/Data/IROS_2022/20220513_TS/2022-05-13-22-35-30.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220513_TS_2/2022-05-13-22-51-40.bag\",\n",
    "        \"/media/william/T7/theodolite_bags/20220523_TS/cones_filtered_2022-05-23-19-31-32.bag\",\n",
    "        \"/media/william/T7/theodolite_bags/20220523_TS/constrained_2022-05-23-18-56-16.bag\",\n",
    "        \"/media/william/T7/theodolite_bags/20220523_TS/empty_filtered_2022-05-23-19-18-35.bag\",\n",
    "        \"/media/william/T7/theodolite_bags/20220523_TS/other_tunnel_2022-05-23-19-39-40.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220525_TS/2022-05-25-11-07-40.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220525_TS/2022-05-25-13-32-32.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220622_TS/2022-06-22-17-48-25.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220622_TS/2022-06-22-18-11-00.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220630_TS/2022-06-30-10-32-21.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220630_TS/2022-06-30-10-57-07.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220711_TS/2022-07-11-15-36-04.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220711_TS/2022-07-11-15-50-00.bag\",\n",
    "#         \"/media/william/T7/theodolite_bags/20220715_TS/2022-07-15-11-50-15.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220715_TS/2022-07-15-11-53-12.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220715_TS/2022-07-15-11-58-58.bag\",\n",
    "#         \"/media/william/T7/theodolite_bags/20220715_TS/2022-07-15-14-42-27.bag\"\n",
    "# #         \"/home/norlab/Data/IROS_2022/20220717_TS/constrained_2022-07-17-20-10-31.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220717_TS/constrained_2022-07-17-20-11-10.bag\",\n",
    "# #         \"/home/norlab/Data/IROS_2022/20220717_TS/cones_2022-07-17-20-38-29.bag\",\n",
    "# #         \"/home/norlab/Data/IROS_2022/20220717_TS/empty_2022-07-17-21-03-14.bag\",\n",
    "        # \"/media/william/T7/theodolite_bags/20220717_TS/calibration_2022-07-17-21-27-28.bag\",\n",
    "        #  \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-12-27-58.bag\",\n",
    "        #  \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-12-29-00.bag\",\n",
    "        #  \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-12-30-49.bag\",\n",
    "        #  \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-12-32-47.bag\",\n",
    "        #  \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-12-34-15.bag\",\n",
    "        #  \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-12-37-00.bag\",\n",
    "         \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-13-37-52.bag\",\n",
    "         \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-13-49-07.bag\",\n",
    "         \"/media/william/T7/theodolite_bags/20220910_TS/2022-09-10-13-58-19.bag\"\n",
    "       ]\n",
    "\n",
    "output = [\n",
    "        # 'TS/20220224/',\n",
    "        # 'TS/20220307/',\n",
    "# #         'TS/20220312/',\n",
    "        # 'TS/20220314/',\n",
    "        # 'TS/20220316/',\n",
    "        'TS/20220331-1/',\n",
    "        # 'TS/20220331-2/',\n",
    "# #         'TS/20220427/',\n",
    "        'TS/20220505_empty/',\n",
    "        'TS/20220505_cones/',\n",
    "#         'TS/20220513/01/',\n",
    "#         'TS/20220513/02/',\n",
    "#         'TS/20220513/03/',\n",
    "        # 'TS/20220513/04/',\n",
    "# #         'TS/20220513/05/',\n",
    "        # 'TS/20220513/06/',\n",
    "        'TS/20220523_cones/',\n",
    "        'TS/20220523_constrained/',\n",
    "        'TS/20220523_empty/',\n",
    "        'TS/20220523_other_tunnel/',\n",
    "        # 'TS/20220525/01/',\n",
    "        # 'TS/20220525/02/',\n",
    "        # 'TS/20220622-1/',\n",
    "        # 'TS/20220622-2/',\n",
    "        # 'TS/20220630-1/',\n",
    "        # 'TS/20220630-2/',\n",
    "        # 'TS/20220711/01/',\n",
    "        # 'TS/20220711/02/',\n",
    "#         'TS/20220715/01/',\n",
    "        # 'TS/20220715/02/',\n",
    "        # 'TS/20220715/03/',\n",
    "#         'TS/20220715/04/'\n",
    "# #         'TS/20220717/01/',\n",
    "        # 'TS/20220717/02/',\n",
    "# #         'TS/20220717/03/',\n",
    "# #         'TS/20220717/04/',\n",
    "        # 'TS/20220717/05/',\n",
    "        # 'TS/20220910/01/',\n",
    "        # 'TS/20220910/02/',\n",
    "        # 'TS/20220910/03/',\n",
    "        # 'TS/20220910/04/',\n",
    "        # 'TS/20220910/05/',\n",
    "        # 'TS/20220910/06/',\n",
    "        'TS/20220910/07/',\n",
    "        'TS/20220910/08/',\n",
    "        'TS/20220910/09/'\n",
    "]\n",
    "\n",
    "# 'f-2-1-1-0.5-6-0-L_',\n",
    "# 'f-2-1-1-0.75-6-0-L_',\n",
    "# 'f-2-1-1-1-6-0-L_',\n",
    "# 'f-2-1-1-1.25-6-0-L_',\n",
    "# 'f-2-1-1-1.5-6-0-L_',\n",
    "# 'f-2-1-1-1.75-6-0-L_',\n",
    "# 'f-2-1-1-2-6-0-L_',\n",
    "# 'f-2-1-1-2.25-6-0-L_',\n",
    "# 'f-2-1-1-2.5-6-0-L_'\n",
    "parameters = [\n",
    "    [0,2,1,1,1,0,2],\n",
    "    [1,2,1,1,1,0,2],\n",
    "    [0,2,1,1,1,0,6],\n",
    "    [1,2,1,1,1,0,6],\n",
    "    # [1,2,1,1,0.5,0,6],\n",
    "    # [1,2,1,1,0.6,0,6],\n",
    "    # [1,2,1,1,0.7,0,6],\n",
    "    # [1,2,1,1,0.8,0,6],\n",
    "    # [1,2,1,1,0.9,0,6],\n",
    "    # [1,2,1,1,1.0,0,6],\n",
    "    # [1,2,1,1,1.1,0,6],\n",
    "    # [1,2,1,1,1.2,0,6],\n",
    "    # [1,2,1,1,1.3,0,6],\n",
    "    # [1,2,1,1,1.4,0,6],\n",
    "    # [1,2,1,1,1.5,0,6],\n",
    "    # [1,2,1,1,1.6,0,6],\n",
    "    # [1,2,1,1,1.7,0,6],\n",
    "    # [1,2,1,1,1.8,0,6],\n",
    "    # [1,2,1,1,1.9,0,6],\n",
    "    # [1,2,1,1,2.0,0,6],\n",
    "    # [1,2,1,1,2.1,0,6],\n",
    "    # [1,2,1,1,2.2,0,6],\n",
    "    # [1,2,1,1,2.3,0,6],\n",
    "    # [1,2,1,1,2.4,0,6],\n",
    "    # [1,2,1,1,2.5,0,6]\n",
    "]\n",
    "\n",
    "for param in parameters:\n",
    "    print(param)\n",
    "    # General parameters \n",
    "    if(param[0]==0):\n",
    "        filtering = False\n",
    "    if(param[0]==1):\n",
    "        filtering = True\n",
    "    thresold_d = param[1]                # m/s\n",
    "    thresold_a = param[2]                # deg/s\n",
    "    thresold_e = param[3]                # deg/s\n",
    "    limit_time_interval = param[4]       # s\n",
    "    path_output = \"./data/prediction/\"\n",
    "    B.epsilon = 1e-8\n",
    "    Mode = \"SGP\"\n",
    "    limit_search = limit_time_interval\n",
    "    delta_t = param[5]               # Value to remove points near edge of time intervals\n",
    "    size_interval = param[6]           # Minimum time size sub-interval \n",
    "    save = True\n",
    "\n",
    "    # GP parameters\n",
    "    verbose=False\n",
    "    Number_restart = 100\n",
    "    noise_GP = 0                # Noise of GP\n",
    "    variance_GP = 1             # Variance of GP\n",
    "    lengthscale_GP = 1          # Lengthscale of GP\n",
    "\n",
    "    save_index_1 = []\n",
    "\n",
    "    for fname, opath in zip(file,output): \n",
    "        if(not filtering):\n",
    "            path = opath + \"raw/\"\n",
    "        else:\n",
    "            path = opath + \"filtered/\"\n",
    "\n",
    "        if(filtering):\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = ttf.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(fname)\n",
    "            index_1_f = ttf.thresold_raw_data(t1, d1, a1, e1, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_2_f = ttf.thresold_raw_data(t2, d2, a2, e2, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_3_f = ttf.thresold_raw_data(t3, d3, a3, e3, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            t1 = t1[index_1_f]\n",
    "            t2 = t2[index_2_f]\n",
    "            t3 = t3[index_3_f]\n",
    "            tp1 = tp1[index_1_f].T\n",
    "            tp2 = tp2[index_2_f].T\n",
    "            tp3 = tp3[index_3_f].T\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "        else:\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = ttf.read_rosbag_theodolite_without_tf_raw_data(fname)\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "\n",
    "        time_origin = np.min([t1[0],t2[0],t3[0]])\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        t1 = t1 - np.ones_like(t1)*time_origin\n",
    "        t2 = t2 - np.ones_like(t2)*time_origin\n",
    "        t3 = t3 - np.ones_like(t3)*time_origin\n",
    "\n",
    "        list_interval, list_time = tfu.split_time_interval_all_data(t1, t2, t3, limit_time_interval)\n",
    "        list_trajectories_split = tfu.merge_interval(list_interval, list_time, t1, t2, t3, limit_search)\n",
    "\n",
    "        Prediction_1 = []\n",
    "        Prediction_2 = []\n",
    "        Prediction_3 = []\n",
    "        T_prediction = []\n",
    "\n",
    "        for i in tqdm(list_trajectories_split):\n",
    "\n",
    "            index_1 = np.array([i[0,0],i[1,0]])\n",
    "            index_2 = np.array([i[0,1],i[1,1]])\n",
    "            index_3 = np.array([i[0,2],i[1,2]])\n",
    "\n",
    "            save_index_1.append(index_1)\n",
    "\n",
    "            if(filtering==True):\n",
    "                index_1 = GPf.delta_t_function(index_1,t1,delta_t)\n",
    "                index_2 = GPf.delta_t_function(index_2,t2,delta_t)\n",
    "                index_3 = GPf.delta_t_function(index_3,t3,delta_t)\n",
    "\n",
    "            begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])\n",
    "            end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])\n",
    "\n",
    "            if(abs(end-begin)>size_interval and begin<end):\n",
    "\n",
    "                rate = 10  #Hz\n",
    "                T_prediction_init = torch.from_numpy(np.arange(begin, end, 1/rate))\n",
    "\n",
    "                if(Mode == \"MGPO\" or Mode == \"All\"):\n",
    "                    T_MGPO, S_MGPO = GPf.data_training_MGPO(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    print(\"Training\")\n",
    "                    m = GPf.training_MGPO(Number_restart, verbose, T_MGPO, S_MGPO)\n",
    "                    print(\"Prediction\")\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                        P1_MGPO, P2_MGPO, P3_MGPO = GPf.unit_prediction_MGPO(i, m)\n",
    "                        Prediction_1.append(P1_MGPO)\n",
    "                        Prediction_2.append(P2_MGPO)\n",
    "                        Prediction_3.append(P3_MGPO)\n",
    "\n",
    "                if(Mode == \"GP\" or Mode == \"All\"):\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = GPf.data_training_GP(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    print(\"Training\")\n",
    "                    mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = GPf.training_GP(Number_restart, verbose, T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3)\n",
    "                    print(\"Prediction\")\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                        P1_GP, P2_GP, P3_GP = GPf.unit_prediction_GP(i, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                        Prediction_1.append(P1_GP)\n",
    "                        Prediction_2.append(P2_GP)\n",
    "                        Prediction_3.append(P3_GP)\n",
    "\n",
    "                if(Mode == \"L\" or Mode == \"All\"):\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = GPf.data_training_L(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    print(\"Prediction\")\n",
    "                    mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = GPf.linear_interpolation(T1, X1, Y1, Z1, T2, X2, Y2, Z2,T3, X3, Y3, Z3)\n",
    "\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                        P1_GP, P2_GP, P3_GP = GPf.linear_prediction(i, time_origin, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                        Prediction_1.append(P1_GP)\n",
    "                        Prediction_2.append(P2_GP)\n",
    "                        Prediction_3.append(P3_GP)\n",
    "\n",
    "                if(Mode==\"SGP\"):\n",
    "                    prediction_value = T_prediction_init.numpy()\n",
    "                    # Prepare data for training\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = GPf.data_training_GP_stheno(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    # Training for each axis\n",
    "                    m_X1, v_X1 = GPf.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=X1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Y1, v_Y1 = GPf.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=Y1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Z1, v_Z1 = GPf.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=Z1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_X2, v_X2 = GPf.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=X2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Y2, v_Y2 = GPf.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=Y2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Z2, v_Z2 = GPf.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=Z2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_X3, v_X3 = GPf.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=X3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Y3, v_Y3 = GPf.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=Y3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Z3, v_Z3 = GPf.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=Z3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "\n",
    "                    # Save prediction at time i\n",
    "                    for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X1, m_Y1, m_Z1, v_X1, v_Y1, v_Z1):\n",
    "                        Prediction_1.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                    for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X2, m_Y2, m_Z2, v_X2, v_Y2, v_Z2):\n",
    "                        Prediction_2.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "                    for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X3, m_Y3, m_Z3, v_X3, v_Y3, v_Z3):\n",
    "                        Prediction_3.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "\n",
    "        stop_time = time.time()\n",
    "        print(stop_time - start_time)\n",
    "\n",
    "        print(\"Interpolation finished !\")\n",
    "\n",
    "        if save:\n",
    "            if(Mode == \"MGPO\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-MGPO-\"+str(Number_restart)\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-MGPO-\"+str(Number_restart)\n",
    "\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "            if(Mode == \"GP\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-GP-\"+str(Number_restart)\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-GP-\"+str(Number_restart)\n",
    "\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "            if(Mode == \"SGP\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-SGP-\"+str(Number_restart)\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-SGP-\"+str(Number_restart)\n",
    "\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "                tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "            if(Mode == \"L\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-L\"\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-L\"\n",
    "\n",
    "                if save:\n",
    "                    tfu.Convert_datap_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "                    tfu.Convert_datap_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "                    tfu.Convert_datap_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "\n",
    "        print(\"Saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b510b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttf = importlib.reload(ttf)\n",
    "tfu = importlib.reload(tfu)\n",
    "\n",
    "k = './data/prediction/TS/20220717/02/'\n",
    "path_type = 'raw/'\n",
    "path_file_type = 'nf-1-6-1-L_'\n",
    "\n",
    "trimble_1 = ttf.read_prediction_data_resection_csv_file(k+path_type+path_file_type+\"1.csv\")\n",
    "t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = ttf.read_rosbag_theodolite_without_tf_raw_data(\"/home/norlab/Data/IROS_2022/20220717_TS/constrained_2022-07-17-20-11-10.bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "save_index_1_arr = np.array(save_index_1)\n",
    "i = save_index_1_arr[20]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(t1,tp1[0,:],s =1)\n",
    "#plt.scatter(t2,tp2[0,:],s =1)\n",
    "\n",
    "plt.scatter(t1[i[0]:i[1]],tp1[0,i[0]:i[1]], linewidth=5, color= 'black')\n",
    "\n",
    "#plt.plot(trimble_1[i[0,0]:i[1,0],0],trimble_1[i[0,0]:i[1,0],1], linewidth=5, color= 'black')\n",
    "#plt.plot(trimble_1[i[0,0]:i[1,0],0],trimble_1[i[0,0]:i[1,0],1], linewidth=5, color= 'black')\n",
    "plt.scatter(trimble_1[:,0],trimble_1[:,1], linewidth=2, color= 'red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544ca35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeMaxVenv",
   "language": "python",
   "name": "codemaxvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
