{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff877c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load Python extension for LZ4 support. LZ4 compression will not be available.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import animation\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import importlib\n",
    "import scripts.theodolite_function as tfu\n",
    "import scripts.theodolite_utils as ttf\n",
    "import GPy\n",
    "import scripts.gp_prediction_utils as GPf\n",
    "tfu = importlib.reload(tfu)\n",
    "ttf = importlib.reload(ttf)\n",
    "GPf = importlib.reload(GPf)\n",
    "\n",
    "from scipy.interpolate import splprep, splev\n",
    "from scipy import interpolate\n",
    "from scipy import spatial\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from IPython.display import HTML\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct, ConstantKernel)\n",
    "from stheno import B, Measure, GP, EQ, Delta\n",
    "import torch\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from wbml.plot import tweak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53e2fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data for theodolites: [1013  992 1013]\n",
      "Bad measures: 52\n",
      "670 670 669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                       | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████████▍                                                                                                                                                                 | 1/13 [00:00<00:02,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "Prediction\n",
      "Prediction\n",
      "Prediction\n",
      "Prediction\n",
      "Prediction\n",
      "0.3764064311981201\n",
      "Interpolation finished !\n",
      "Conversion done !\n",
      "Conversion done !\n",
      "Conversion done !\n",
      "Saved !\n"
     ]
    }
   ],
   "source": [
    "# Read rosbag of grand axe and show the trajectory\n",
    "ttf = importlib.reload(ttf)\n",
    "tfu = importlib.reload(tfu)\n",
    "GPf = importlib.reload(GPf)\n",
    "\n",
    "\n",
    "# file = [\"/home/norlab/Data/IROS_2022/20220224_TS/2022-02-24-15-34-38.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220307_TS/2022-03-07-19-20-06.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220312_TS/2022-03-12-09-45-12.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220314_TS/2022-03-14-10-47-49.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220316_TS/2022-03-16-19-02-42.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220331_TS/2022-03-31-10-22-52.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220331_TS/2022-03-31-11-20-05.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220427_TS/2022-04-27-12-12-10_filered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220505_TS/empty1_2022-05-05-19-14-33.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20220505_TS/cones1_2022-05-05-19-25-54.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201007_Foret/2020-10-08-11-57-30_one_prism_continuous_mapping_quarry1_filtered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201007_Foret/2020-10-08-12-14-23_three_prism_continuos_mapping_quarry2_filtered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201007_Foret/2020-10-08-17-58-38_ski_trail_continuous_motion_filtered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201007_Foret/2020-10-08-18-01-19_ski_trail_start_stop_motion_filtered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201007_Foret/2020-10-08-18-05-08_ski_trail_start_stop_straight_segment_filtered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201201_Foret/2020-12-01-17-29-01_theodolite.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201201_Foret/2020-12-01-18-00-21_theodolite.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201201_Foret/2020-12-01-18-15-43_theodolite.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201202_Foret/2020-12-02-11-37-05_theodolite.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201202_Foret/2020-12-02-12-28-41_theodolite.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20201203_Foret/2020-12-03-10-21-59_theodolite.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20210222_Foret/2021-02-22-15-43-34_filtered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20210222_Foret/2021-02-22-15-50-23_filtered.bag\",\n",
    "#         \"/home/norlab/Data/IROS_2022/20210222_Foret/2021-02-22-16-01-10_filtered.bag\"]\n",
    "\n",
    "# output = [\"TS/20220224/\",\n",
    "#          \"TS/20220307/\",\n",
    "#          \"TS/20220312/\",\n",
    "#          \"TS/20220314/\",\n",
    "#          \"TS/20220316/\",\n",
    "#          \"TS/20220331-1/\",\n",
    "#          \"TS/20220331-2/\",\n",
    "#          \"TS/20220427/\",\n",
    "#          \"TS/20220505_empty/\",\n",
    "#          \"TS/20220505_cones/\",\n",
    "#          \"TS/20201007/01/\",\n",
    "#          \"TS/20201007/02/\",\n",
    "#          \"TS/20201007/03/\",\n",
    "#          \"TS/20201007/04/\",\n",
    "#          \"TS/20201007/05/\",\n",
    "#          \"TS/20201201/01/\",\n",
    "#          \"TS/20201201/02/\",\n",
    "#          \"TS/20201201/03/\",\n",
    "#          \"TS/20201202/01/\",\n",
    "#          \"TS/20201202/02/\",\n",
    "#          \"TS/20201203/01/\",\n",
    "#          \"TS/20210222/01/\",\n",
    "#          \"TS/20210222/02/\",\n",
    "#          \"TS/20210222/03/\"]\n",
    "\n",
    "\n",
    "file = [\"/media/will/T7/theodolite_bags/20220711_TS/2022-07-11-15-36-04.bag\"]\n",
    "\n",
    "output = [\"TS/20220711/dynamic_control_points/\"]\n",
    "\n",
    "\n",
    "\n",
    "# General parameters \n",
    "filtering = True\n",
    "thresold_d = 2                 # m/s\n",
    "thresold_a = 1                 # deg/s\n",
    "thresold_e = 1                 # deg/s\n",
    "limit_time_interval = 1        # s\n",
    "path_output = \"./data/prediction/\"\n",
    "B.epsilon = 1e-8\n",
    "Mode = \"L\"\n",
    "limit_search = limit_time_interval\n",
    "size_interval = 6           # Minimum time size sub-interval \n",
    "delta_t = 1                 # Value to remove points near edge of time intervals\n",
    "save = True\n",
    "\n",
    "# GP parameters\n",
    "verbose=False\n",
    "Number_restart = 1000\n",
    "noise_GP = 0                # Noise of GP\n",
    "variance_GP = 1             # Variance of GP\n",
    "lengthscale_GP = 1          # Lengthscale of GP\n",
    "\n",
    "for fname, opath in zip(file,output): \n",
    "    if(not filtering):\n",
    "        path = opath + \"raw/\"\n",
    "    else:\n",
    "        path = opath + \"filtered/\"\n",
    "        \n",
    "    if(filtering):\n",
    "        t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = ttf.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(fname)\n",
    "        index_1_f = ttf.thresold_raw_data(t1, d1, a1, e1, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "        index_2_f = ttf.thresold_raw_data(t2, d2, a2, e2, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "        index_3_f = ttf.thresold_raw_data(t3, d3, a3, e3, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "        t1 = t1[index_1_f]\n",
    "        t2 = t2[index_2_f]\n",
    "        t3 = t3[index_3_f]\n",
    "        tp1 = tp1[index_1_f].T\n",
    "        tp2 = tp2[index_2_f].T\n",
    "        tp3 = tp3[index_3_f].T\n",
    "        print(len(t1),len(t2),len(t3))\n",
    "    else:\n",
    "        t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = ttf.read_rosbag_theodolite_without_tf_raw_data(fname)\n",
    "        print(len(t1),len(t2),len(t3))\n",
    "\n",
    "    time_origin = np.min([t1[0],t2[0],t3[0]])\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    t1 = t1 - np.ones_like(t1)*time_origin\n",
    "    t2 = t2 - np.ones_like(t2)*time_origin\n",
    "    t3 = t3 - np.ones_like(t3)*time_origin\n",
    "\n",
    "    list_interval, list_time = tfu.split_time_interval_all_data(t1, t2, t3, limit_time_interval)\n",
    "    list_trajectories_split = tfu.merge_interval(list_interval, list_time, t1, t2, t3, limit_search)\n",
    "\n",
    "    Prediction_1 = []\n",
    "    Prediction_2 = []\n",
    "    Prediction_3 = []\n",
    "    T_prediction = []\n",
    "\n",
    "    for i in tqdm(list_trajectories_split):\n",
    "\n",
    "        index_1 = np.array([i[0,0],i[1,0]])\n",
    "        index_2 = np.array([i[0,1],i[1,1]])\n",
    "        index_3 = np.array([i[0,2],i[1,2]])\n",
    "\n",
    "        begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])+delta_t\n",
    "        end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])-delta_t\n",
    "\n",
    "        if(abs(end-begin)>size_interval and begin<end):\n",
    "\n",
    "            rate = 10  #Hz\n",
    "            T_prediction_init = torch.from_numpy(np.arange(begin, end, 1/rate))\n",
    "\n",
    "            if(Mode == \"MGPO\" or Mode == \"All\"):\n",
    "                T_MGPO, S_MGPO = GPf.data_training_MGPO(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                print(\"Training\")\n",
    "                m = GPf.training_MGPO(Number_restart, verbose, T_MGPO, S_MGPO)\n",
    "                print(\"Prediction\")\n",
    "                for i in T_prediction_init.numpy():\n",
    "                    T_prediction.append(i+time_origin)\n",
    "                    P1_MGPO, P2_MGPO, P3_MGPO = GPf.unit_prediction_MGPO(i, m)\n",
    "                    Prediction_1.append(P1_MGPO)\n",
    "                    Prediction_2.append(P2_MGPO)\n",
    "                    Prediction_3.append(P3_MGPO)\n",
    "\n",
    "            if(Mode == \"GP\" or Mode == \"All\"):\n",
    "                T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = GPf.data_training_GP(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                print(\"Training\")\n",
    "                mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = GPf.training_GP(Number_restart, verbose, T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3)\n",
    "                print(\"Prediction\")\n",
    "                for i in T_prediction_init.numpy():\n",
    "                    T_prediction.append(i+time_origin)\n",
    "                    P1_GP, P2_GP, P3_GP = GPf.unit_prediction_GP(i, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                    Prediction_1.append(P1_GP)\n",
    "                    Prediction_2.append(P2_GP)\n",
    "                    Prediction_3.append(P3_GP)\n",
    "\n",
    "            if(Mode == \"L\" or Mode == \"All\"):\n",
    "                T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = GPf.data_training_L(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                print(\"Prediction\")\n",
    "                mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = GPf.linear_interpolation(T1, X1, Y1, Z1, T2, X2, Y2, Z2,T3, X3, Y3, Z3)\n",
    "\n",
    "                for i in T_prediction_init.numpy():\n",
    "                    T_prediction.append(i+time_origin)\n",
    "                    P1_GP, P2_GP, P3_GP = GPf.linear_prediction(i, time_origin, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                    Prediction_1.append(P1_GP)\n",
    "                    Prediction_2.append(P2_GP)\n",
    "                    Prediction_3.append(P3_GP)\n",
    "\n",
    "            if(Mode==\"SGP\"):\n",
    "                prediction_value = T_prediction_init.numpy()\n",
    "                # Prepare data for training\n",
    "                T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = GPf.data_training_GP_stheno(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                # Training for each axis\n",
    "                m_X1, v_X1 = GPf.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=X1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_Y1, v_Y1 = GPf.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=Y1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_Z1, v_Z1 = GPf.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=Z1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_X2, v_X2 = GPf.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=X2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_Y2, v_Y2 = GPf.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=Y2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_Z2, v_Z2 = GPf.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=Z2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_X3, v_X3 = GPf.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=X3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_Y3, v_Y3 = GPf.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=Y3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                m_Z3, v_Z3 = GPf.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=Z3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "\n",
    "                # Save prediction at time i\n",
    "                for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X1, m_Y1, m_Z1, v_X1, v_Y1, v_Z1):\n",
    "                    Prediction_1.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "                    T_prediction.append(i+time_origin)\n",
    "                for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X2, m_Y2, m_Z2, v_X2, v_Y2, v_Z2):\n",
    "                    Prediction_2.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "                for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X3, m_Y3, m_Z3, v_X3, v_Y3, v_Z3):\n",
    "                    Prediction_3.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "\n",
    "    stop_time = time.time()\n",
    "    print(stop_time - start_time)\n",
    "\n",
    "    print(\"Interpolation finished !\")\n",
    "\n",
    "    if save:\n",
    "        if(Mode == \"MGPO\" or Mode == \"All\"):\n",
    "            if(filtering):\n",
    "                trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-MGPO-\"+str(Number_restart)\n",
    "            else:\n",
    "                trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-MGPO-\"+str(Number_restart)\n",
    "\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "        if(Mode == \"GP\" or Mode == \"All\"):\n",
    "            if(filtering):\n",
    "                trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-GP-\"+str(Number_restart)\n",
    "            else:\n",
    "                trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-GP-\"+str(Number_restart)\n",
    "\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "        if(Mode == \"SGP\" or Mode == \"All\"):\n",
    "            if(filtering):\n",
    "                trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-SGP-\"+str(Number_restart)\n",
    "            else:\n",
    "                trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-SGP-\"+str(Number_restart)\n",
    "\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "            tfu.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "        if(Mode == \"L\" or Mode == \"All\"):\n",
    "            if(filtering):\n",
    "                trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-L\"\n",
    "            else:\n",
    "                trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-L\"\n",
    "\n",
    "            if save:\n",
    "                tfu.Convert_datap_to_csv(T_prediction, Prediction_1, path_output+path+trajectoire+ \"_1.csv\")\n",
    "                tfu.Convert_datap_to_csv(T_prediction, Prediction_2, path_output+path+trajectoire+ \"_2.csv\")\n",
    "                tfu.Convert_datap_to_csv(T_prediction, Prediction_3, path_output+path+trajectoire+ \"_3.csv\")\n",
    "\n",
    "    print(\"Saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b510b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeMax_venv",
   "language": "python",
   "name": "codemax_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
