{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scripts.prediction_utils as predict_u\n",
    "import scripts.theodolite_utils as theodo_u\n",
    "import scripts.theodolite_plot_function as theodo_p\n",
    "import scripts.groundtruth_utils as theodo_g\n",
    "import scripts.theodolite_function as theodo_f\n",
    "import time\n",
    "import torch\n",
    "from numpy import linalg\n",
    "import importlib\n",
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_p = importlib.reload(theodo_p)\n",
    "theodo_f = importlib.reload(theodo_f)\n",
    "predict_u = importlib.reload(predict_u)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:29:23.418453611Z",
     "start_time": "2023-05-18T17:29:23.368768225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## Path of main data files\n",
    "type_file_input = \"CSV\"    ## CSV or ROSBAG\n",
    "\n",
    "path = [\n",
    "    # \"../data/20220224/\",\n",
    "    \"../data/20220307/\",\n",
    "    # \"../data/20220312/\",          # Weird pic in extrinsic calibration\n",
    "    # \"../data/20220314/\",\n",
    "    # \"../data/20220316/\",\n",
    "    # \"../data/20220331-1/\",\n",
    "    # \"../data/20220331-2/\",\n",
    "    # \"../data/20220427-1/\",        # Weird pic in extrinsic calibration\n",
    "    # \"../data/20220427-2/\",        # Weird pic in extrinsic calibration\n",
    "    # \"../data/20220513-1/\",\n",
    "    # \"../data/20220513-2/\",\n",
    "    # \"../data/20220513-3/\",\n",
    "    # \"../data/20220513-4/\",\n",
    "    # \"../data/20220513-5/\",\n",
    "    # \"../data/20220513-6/\",\n",
    "    # \"../data/20220525-1/\",\n",
    "    # \"../data/20220525-2/\",\n",
    "    # \"../data/20220622-1/\",\n",
    "    # \"../data/20220622-2/\",\n",
    "    # \"../data/20220630-1/\",\n",
    "    # \"../data/20220630-2/\",\n",
    "    # \"../data/20220711-1/\",\n",
    "    # \"../data/20220711-2/\",\n",
    "    # \"../data/20220715-1/\",\n",
    "    # \"../data/20220715-2/\",\n",
    "    # \"../data/20220715-3/\",\n",
    "    # \"../data/20220715-4/\",\n",
    "    # \"../data/20221103-1/\",\n",
    "    # \"../data/20221103-2/\",\n",
    "    # \"../data/20221103-3/\",\n",
    "    # \"../data/20221109-1/\",\n",
    "    # \"../data/20221109-2/\",\n",
    "    # \"../data/20221109-3/\",\n",
    "    # \"../data/20221110/\",\n",
    "    # \"../data/20221116-1/\",\n",
    "    # \"../data/20221123/\",\n",
    "    # \"../data/20221124/\",\n",
    "    # \"../data/20221129-1/\",\n",
    "    # \"../data/20221129-2/\",\n",
    "    # \"../data/20221129-3/\",\n",
    "    # \"../data/20221129-4/\",\n",
    "    # \"../data/20221129-5/\",\n",
    "    # \"../data/20221205-1/\",\n",
    "    # \"../data/20221205-2/\",\n",
    "    # \"../data/20221205-3/\"\n",
    "]\n",
    "\n",
    "parameters = [\n",
    "    [1,2,1,1,3,2],  # 1. Apply filtering or not (Module 1), 2-3-4. Parameters tau_r, tau_a, tau_e (Module 1), 5. Parameter tau_s (Module 2), 6 Parameter tau_l (Module 4).\n",
    "]\n",
    "\n",
    "# Reading sensor data\n",
    "# Sensor = \"Robosense_32\"\n",
    "Sensor = \"Fake\"   # GNSS or Robosense_32 or Fake\n",
    "# path_sensor_file = path+\"ICP/icp_odom.csv\"\n",
    "rate_fake = 5  # Hz\n",
    "Sensor_fake = \"GNSS\"\n",
    "path_sensor_file = \"gps_data/\"+\"gps1.txt\"\n",
    "path_sensor_file_synch_time = \"gps_data/delay_synchronization_GNSS_1.txt\"  # If applied to GNSS\n",
    "Gps_reference_chosen = 1    # 1: front, 2: back, 3: middle   # Only for GNSS\n",
    "\n",
    "# Limit acceptable for ground truth error\n",
    "limit_taken_into_accout = False\n",
    "limit_dist = 100  # Need to check the impact\n",
    "limit_uncertainty = 100 # Limit of eigenvalues taken into account\n",
    "\n",
    "## Parameters about noise for MC\n",
    "## Number sample MC\n",
    "num_samples = 1000\n",
    "## Range noise\n",
    "random_noise_range = [0, 0.004/2, 2]   ## Mean, sigma, ppm,  4mm + 2ppm (2 sigma)  ISO17123-3\n",
    "## Angles noise\n",
    "random_noise_angle = [0, 0.000024241/5*4/2]    # Mean, sigma, 5\"=0.000024241 precision datasheet  (2 sigma)  ISO17123-3\n",
    "## Tilt compensator noise\n",
    "random_noise_tilt = [0, 0.000002424/2]    # Mean, sigma, 0.5\"=0.000002424 precision datasheet  (2 sigma)  ISO17123-3\n",
    "## Weather conditions\n",
    "weather_data_path = \"../data/weather_2022/Quebec/\"\n",
    "data_weather = np.array(theodo_u.read_weather_data(weather_data_path+\"data_sorted_2022.txt\"))\n",
    "## Time synchronization\n",
    "time_error_synch_mean = 1.157*10**(-3)  # Mean time error [s]\n",
    "time_error_synch_std = 0.815*10**(-3)   # Std time error [s]\n",
    "## Choice of noise model\n",
    "model_chosen = [0, 0, 1, 0, 0]  # Tilt noise, Atmospheric correction, extrinsic calibration, Time synchronization, Weather corrections # 1: Activate, 0:Disable\n",
    "\n",
    "num_samples_MC_sensor = 100   ## Number sample for uncertainty propagation to the sensor\n",
    "save_MC_inteprolated = True   ## Save interpolation done with STEAM\n",
    "want_sensor_pose = True      ## Compute sensor uncertainty\n",
    "save_MC_sensor = False        ## Save sensor pose with uncertainty"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:29:24.355935567Z",
     "start_time": "2023-05-18T17:29:24.326231806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed:  ../data/20220307/\n",
      "Parameters used:  [1, 2, 1, 1, 3, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/repos/RTS_Extrinsic_Calibration/scripts/theodolite_utils.py:1718: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array_point = np.array([Time, D, A, E, Speed, Speed_sigma])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sub-trajectories : 65\n",
      "Sub-trajectories 0\n",
      "Number of input:  368\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time [s]:  141.55\n",
      "Sub-trajectories 1\n",
      "Number of input:  65\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time [s]:  26.34\n",
      "Sub-trajectories 2\n",
      "Sub-trajectories 3\n",
      "Sub-trajectories 4\n",
      "Sub-trajectories 5\n",
      "Sub-trajectories 6\n",
      "Sub-trajectories 7\n",
      "Sub-trajectories 8\n",
      "Sub-trajectories 9\n",
      "Sub-trajectories 10\n",
      "Sub-trajectories 11\n",
      "Sub-trajectories 12\n",
      "Sub-trajectories 13\n",
      "Sub-trajectories 14\n",
      "Sub-trajectories 15\n",
      "Sub-trajectories 16\n",
      "Sub-trajectories 17\n",
      "Sub-trajectories 18\n",
      "Sub-trajectories 19\n",
      "Sub-trajectories 20\n",
      "Sub-trajectories 21\n",
      "Sub-trajectories 22\n",
      "Sub-trajectories 23\n",
      "Sub-trajectories 24\n",
      "Sub-trajectories 25\n",
      "Sub-trajectories 26\n",
      "Sub-trajectories 27\n",
      "Sub-trajectories 28\n",
      "Sub-trajectories 29\n",
      "Sub-trajectories 30\n",
      "Sub-trajectories 31\n",
      "Sub-trajectories 32\n",
      "Sub-trajectories 33\n",
      "Sub-trajectories 34\n",
      "Sub-trajectories 35\n",
      "Sub-trajectories 36\n",
      "Sub-trajectories 37\n",
      "Sub-trajectories 38\n",
      "Sub-trajectories 39\n",
      "Sub-trajectories 40\n",
      "Sub-trajectories 41\n",
      "Sub-trajectories 42\n",
      "Sub-trajectories 43\n",
      "Sub-trajectories 44\n",
      "Sub-trajectories 45\n",
      "Sub-trajectories 46\n",
      "Sub-trajectories 47\n",
      "Sub-trajectories 48\n",
      "Sub-trajectories 49\n",
      "Sub-trajectories 50\n",
      "Sub-trajectories 51\n",
      "Sub-trajectories 52\n",
      "Sub-trajectories 53\n",
      "Sub-trajectories 54\n",
      "Sub-trajectories 55\n",
      "Sub-trajectories 56\n",
      "Sub-trajectories 57\n",
      "Sub-trajectories 58\n",
      "Sub-trajectories 59\n",
      "Sub-trajectories 60\n",
      "Sub-trajectories 61\n",
      "Sub-trajectories 62\n",
      "Sub-trajectories 63\n",
      "Sub-trajectories 64\n",
      "Conversion done !\n",
      "Conversion done !\n",
      "Conversion done !\n",
      "../data/20220307/ GNSS 1\n",
      "\n",
      "../data/20220307/sensors_extrinsic_calibration/sensor_positions.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [16], line 275\u001B[0m\n\u001B[1;32m    273\u001B[0m             T \u001B[38;5;241m=\u001B[39m theodo_u\u001B[38;5;241m.\u001B[39mpoint_to_point_minimization(P_sensor, Q)\n\u001B[1;32m    274\u001B[0m             Pose_sensor\u001B[38;5;241m.\u001B[39mappend(T)\n\u001B[0;32m--> 275\u001B[0m         p_T, mu_T, cov_T \u001B[38;5;241m=\u001B[39m theodo_g\u001B[38;5;241m.\u001B[39mfind_noise_list_tf(Pose_sensor)\n\u001B[1;32m    276\u001B[0m         Pose_sensor_MC\u001B[38;5;241m.\u001B[39mappend([i_mc[\u001B[38;5;241m0\u001B[39m],mu_T, cov_T])\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save_MC_sensor:\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_p = importlib.reload(theodo_p)\n",
    "predict_u = importlib.reload(predict_u)\n",
    "theodo_g = importlib.reload(theodo_g)\n",
    "\n",
    "for file_i in path:\n",
    "    print(\"File processed: \", file_i)\n",
    "    # Reading sensor extrinsic calibration\n",
    "    file_sensors = theodo_u.if_file_exist(file_i + \"sensors_extrinsic_calibration/calibration_results.csv\",'')\n",
    "    extrinsic_calibration_results = theodo_u.read_extrinsic_calibration_results_file(file_sensors)\n",
    "\n",
    "    ## Read sensor data which we want a ground truth\n",
    "    sensor_data = []\n",
    "    if Sensor == \"GNSS\":\n",
    "        GNSS_raw_data = theodo_u.read_prediction_data_Linear_csv_file(file_i+path_sensor_file)\n",
    "        time_delay = float(theodo_u.read_time_delay(file_i+path_sensor_file_synch_time))\n",
    "\n",
    "        for i in GNSS_raw_data:\n",
    "            raw_data = np.array([i[0] + time_delay, i[1], i[2], i[3], 0, 0, 0, 1])\n",
    "            sensor_data.append(raw_data)\n",
    "        sensor_data = np.array(sensor_data)\n",
    "\n",
    "    if Sensor == \"Robosense_32\":\n",
    "        sensor_data = theodo_u.read_icp_odom_file(file_i+path_sensor_file)\n",
    "        sensor_data = np.array(sensor_data)\n",
    "\n",
    "    ## Number of rigid transforms to apply the uncertainty\n",
    "    path_file_GCP = \"total_stations/GCP.txt\"\n",
    "    frame_chosen, T_1_corrected, T_2_corrected, T_3_corrected = theodo_g.extrinsic_calibration_noise(file_i+path_file_GCP, random_noise_range, random_noise_angle, random_noise_tilt, num_samples)\n",
    "    ## Read Extrinsic results for RTS\n",
    "    ## Estimated extrinsic calibration uncertainty\n",
    "    _, _, _, Tf_1, Tf_2, Tf_3 = theodo_u.read_marker_file(file_i+path_file_GCP, 1, 1)\n",
    "\n",
    "    for param in parameters:\n",
    "        print(\"Parameters used: \", param)\n",
    "\n",
    "        ## Parameters to process the rosbag data\n",
    "        if param[0] == 0:\n",
    "            filtering = False\n",
    "        if param[0] == 1:\n",
    "            filtering = True\n",
    "        thresold_d = param[1]  ## tau_r [m/s]\n",
    "        thresold_a = param[2]  ## tau_a [deg/s]\n",
    "        thresold_e = param[3]  ## tau_e [deg/s]\n",
    "        limit_time_interval = param[4]  ## tau_s [s]\n",
    "        limit_search = limit_time_interval\n",
    "        size_interval = param[5]    ## tau_l\n",
    "        Mode = \"STEAM\"  ## Interpolation choice: 1. L -> Linear interpolation, 2. SGP -> Gaussian Process with Stheno library, 3. STEAM\n",
    "\n",
    "        ## Open rosbag with outlier filters\n",
    "        # if type_file_input==\"ROSBAG\":\n",
    "        #     if filtering:\n",
    "        #         t1, t2, t3, _, _, _, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(\n",
    "        #             file_d)\n",
    "        #         index_1_f = theodo_u.thresold_raw_data(t1, d1, a1, e1, thresold_d, thresold_a * 3.1415926 / 180,\n",
    "        #                                                thresold_e * 3.1415926 / 180, limit_time_interval)\n",
    "        #         index_2_f = theodo_u.thresold_raw_data(t2, d2, a2, e2, thresold_d, thresold_a * 3.1415926 / 180,\n",
    "        #                                                thresold_e * 3.1415926 / 180, limit_time_interval)\n",
    "        #         index_3_f = theodo_u.thresold_raw_data(t3, d3, a3, e3, thresold_d, thresold_a * 3.1415926 / 180,\n",
    "        #                                                thresold_e * 3.1415926 / 180, limit_time_interval)\n",
    "        #         t1 = t1[index_1_f]\n",
    "        #         t2 = t2[index_2_f]\n",
    "        #         t3 = t3[index_3_f]\n",
    "        #         print(\"Size of prism measurements 1, 2 and 3: \", len(t1), len(t2), len(t3))\n",
    "        #     else:\n",
    "        #         t1, t2, t3, _, _, _, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data(\n",
    "        #             file_d)\n",
    "        #         print(\"Size of prism measurements 1, 2 and 3: \", len(t1), len(t2), len(t3))\n",
    "\n",
    "        if type_file_input==\"CSV\":\n",
    "            sub_path = \"uncertainty/raw_data/\"\n",
    "            P1 = theodo_u.read_raw_data_uncertainty_speed(file_i+sub_path+\"speed_prism1.csv\")\n",
    "            P2 = theodo_u.read_raw_data_uncertainty_speed(file_i+sub_path+\"speed_prism2.csv\")\n",
    "            P3 = theodo_u.read_raw_data_uncertainty_speed(file_i+sub_path+\"speed_prism3.csv\")\n",
    "            t1, t2, t3, d1, d2, d3, a1, a2, a3, e1, e2, e3, s1, s2, s3, ss1, ss2, ss3 = ([] for i in range(18))\n",
    "            for p1_i, p2_i, p3_i in zip(P1, P2, P3):\n",
    "                t1.append(p1_i[0])\n",
    "                t2.append(p2_i[0])\n",
    "                t3.append(p3_i[0])\n",
    "                d1.append(p1_i[1])\n",
    "                d2.append(p2_i[1])\n",
    "                d3.append(p3_i[1])\n",
    "                a1.append(p1_i[2])\n",
    "                a2.append(p2_i[2])\n",
    "                a3.append(p3_i[2])\n",
    "                e1.append(p1_i[3])\n",
    "                e2.append(p2_i[3])\n",
    "                e3.append(p3_i[3])\n",
    "                s1.append(p1_i[4])\n",
    "                s2.append(p2_i[4])\n",
    "                s3.append(p3_i[4])\n",
    "                ss1.append(p1_i[5])\n",
    "                ss2.append(p2_i[5])\n",
    "                ss3.append(p3_i[5])\n",
    "            t1 = np.array(t1)\n",
    "            t2 = np.array(t2)\n",
    "            t3 = np.array(t3)\n",
    "            d1 = np.array(d1)\n",
    "            d2 = np.array(d2)\n",
    "            d3 = np.array(d3)\n",
    "            a1 = np.array(a1)\n",
    "            a2 = np.array(a2)\n",
    "            a3 = np.array(a3)\n",
    "            e1 = np.array(e1)\n",
    "            e2 = np.array(e2)\n",
    "            e3 = np.array(e3)\n",
    "            s1 = np.array(s1)\n",
    "            s2 = np.array(s2)\n",
    "            s3 = np.array(s3)\n",
    "            ss1 = np.array(ss1)\n",
    "            ss2 = np.array(ss2)\n",
    "            ss3 = np.array(ss3)\n",
    "\n",
    "        ## Split trajectories according to tau_s\n",
    "        list_interval, list_time = theodo_f.split_time_interval_all_data(t1, t2, t3, limit_time_interval)\n",
    "        list_trajectories_split = theodo_f.merge_interval(list_interval, list_time, t1, t2, t3, limit_search)\n",
    "\n",
    "        M_1_before_inter = []\n",
    "        M_2_before_inter = []\n",
    "        M_3_before_inter = []\n",
    "        Prediction_1 = []\n",
    "        Prediction_2 = []\n",
    "        Prediction_3 = []\n",
    "        T_prediction = []\n",
    "        Index_sensor = []\n",
    "\n",
    "        print(\"Number of sub-trajectories :\", len(list_trajectories_split))\n",
    "        number_ite = 0\n",
    "        ## Process each of the sub-trajectories\n",
    "        for i in list_trajectories_split:\n",
    "            print(\"Sub-trajectories \" + str(number_ite))\n",
    "            number_ite = number_ite + 1\n",
    "            index_1 = np.array([i[0, 0], i[1, 0]])\n",
    "            index_2 = np.array([i[0, 1], i[1, 1]])\n",
    "            index_3 = np.array([i[0, 2], i[1, 2]])\n",
    "\n",
    "            begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])\n",
    "            end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])\n",
    "\n",
    "            if abs(end - begin) > size_interval and begin < end and number_ite<3:  # control number of sample\n",
    "\n",
    "                ## If fake querrying, apply desired rate\n",
    "                T_prediction_sensor = []\n",
    "                if Sensor!=\"Fake\":\n",
    "                    Number = 0\n",
    "                    for value_sensor_data in sensor_data:\n",
    "                        if end >= value_sensor_data[0] >= begin:\n",
    "                            T_prediction_sensor.append(value_sensor_data[0])\n",
    "                            Index_sensor.append(Number)\n",
    "                        Number = Number + 1\n",
    "\n",
    "                    T_prediction_init = torch.from_numpy(np.array(T_prediction_sensor))\n",
    "                else:\n",
    "                    List_time = np.arange(begin, end, 1/rate_fake)\n",
    "                    for i in List_time:\n",
    "                        T_prediction_sensor.append(i)\n",
    "                    T_prediction_init = torch.from_numpy(np.arange(begin, end, 1/rate_fake))\n",
    "\n",
    "                if Mode == \"STEAM\" or Mode == \"All\":\n",
    "\n",
    "                    MC_1 = []\n",
    "                    MC_2 = []\n",
    "                    MC_3 = []\n",
    "                    tic = time.perf_counter()\n",
    "                    ## Compute uncertainty\n",
    "                    T1, D1, A1, E1, S1, SS1 = predict_u.data_training_L_Raw_data(t1, d1, a1, e1, s1, ss1, index_1)\n",
    "                    T2, D2, A2, E2, S2, SS2 = predict_u.data_training_L_Raw_data(t2, d2, a2, e2, s2, ss2, index_2)\n",
    "                    T3, D3, A3, E3, S3, SS3 = predict_u.data_training_L_Raw_data(t3, d3, a3, e3, s3, ss3, index_3)\n",
    "                    print(\"Number of input: \", len(T1))\n",
    "\n",
    "                    for i1,j1,k1,l1,m1,n1 in zip(T1,D1,A1,E1,S1,SS1):\n",
    "                        mu_raw_data, _,cov_matrix_simulated = theodo_g.MC_raw_data(num_samples, j1, random_noise_range, k1, l1, random_noise_angle, random_noise_tilt, Tf_1, T_1_corrected, data_weather, i1, m1, n1, time_error_synch_mean, time_error_synch_std, model_chosen)\n",
    "                        MC_1.append([i1,mu_raw_data,cov_matrix_simulated])\n",
    "                        M_1_before_inter.append([i1,mu_raw_data,cov_matrix_simulated])\n",
    "                    for i2,j2,k2,l2,m2,n2 in zip(T2,D2,A2,E2,S2,SS2):\n",
    "                        mu_raw_data, _,cov_matrix_simulated = theodo_g.MC_raw_data(num_samples, j2, random_noise_range, k2, l2, random_noise_angle, random_noise_tilt, Tf_2, T_2_corrected, data_weather, i2, m2, n2, time_error_synch_mean, time_error_synch_std, model_chosen)\n",
    "                        MC_2.append([i2,mu_raw_data,cov_matrix_simulated])\n",
    "                        M_2_before_inter.append([i2,mu_raw_data,cov_matrix_simulated])\n",
    "                    for i3,j3,k3,l3,m3,n3 in zip(T3,D3,A3,E3,S3,SS3):\n",
    "                        mu_raw_data, _,cov_matrix_simulated = theodo_g.MC_raw_data(num_samples, j3, random_noise_range, k3, l3, random_noise_angle, random_noise_tilt, Tf_3, T_3_corrected, data_weather, i3, m3, n3, time_error_synch_mean, time_error_synch_std, model_chosen)\n",
    "                        MC_3.append([i3,mu_raw_data,cov_matrix_simulated])\n",
    "                        M_3_before_inter.append([i3,mu_raw_data,cov_matrix_simulated])\n",
    "\n",
    "                    ## STEAM\n",
    "                    MC_1_interpolated = theodo_g.STEAM_interpolation_with_covariance(T1, T_prediction_sensor, MC_1)\n",
    "                    MC_2_interpolated = theodo_g.STEAM_interpolation_with_covariance(T2, T_prediction_sensor, MC_2)\n",
    "                    MC_3_interpolated = theodo_g.STEAM_interpolation_with_covariance(T3, T_prediction_sensor, MC_3)\n",
    "                    toc = time.perf_counter()\n",
    "                    print(\"Time [s]: \", round(toc-tic,2))\n",
    "                    if(len(MC_1_interpolated)>0 and len(MC_2_interpolated)>0 and len(MC_3_interpolated)>0):\n",
    "                        Prediction_1.append(MC_1_interpolated)\n",
    "                        Prediction_2.append(MC_2_interpolated)\n",
    "                        Prediction_3.append(MC_3_interpolated)\n",
    "                        T_prediction.append(T_prediction_sensor)\n",
    "\n",
    "        MC_1_inter = []\n",
    "        MC_2_inter = []\n",
    "        MC_3_inter = []\n",
    "        for i1,j1,k1 in zip(Prediction_1,Prediction_2,Prediction_3):\n",
    "            for i2,j2,k2 in zip(i1,j1,k1):\n",
    "                # Check on uncertainty. If too high, remove triplet\n",
    "                if limit_taken_into_accout:\n",
    "                    eig1 = np.linalg.eigvals(i2[2])**0.5\n",
    "                    eig2 = np.linalg.eigvals(j2[2])**0.5\n",
    "                    eig3 = np.linalg.eigvals(k2[2])**0.5\n",
    "                    if eig1[0]<limit_uncertainty and eig1[1]<limit_uncertainty and eig1[2]<limit_uncertainty \\\n",
    "                            and eig2[0]<limit_uncertainty and eig2[1]<limit_uncertainty and eig2[2]<limit_uncertainty \\\n",
    "                            and eig3[0]<limit_uncertainty and eig3[1]<limit_uncertainty and eig3[2]<limit_uncertainty:\n",
    "                        MC_1_inter.append(i2)\n",
    "                        MC_2_inter.append(j2)\n",
    "                        MC_3_inter.append(k2)\n",
    "                else:\n",
    "                    MC_1_inter.append(i2)\n",
    "                    MC_2_inter.append(j2)\n",
    "                    MC_3_inter.append(k2)\n",
    "\n",
    "        if save_MC_inteprolated:\n",
    "            if Sensor!=\"Fake\":\n",
    "                theodo_u.save_MC_interpolated_sorted(MC_1_inter, file_i + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])+\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_1.csv\")\n",
    "                theodo_u.save_MC_interpolated_sorted(MC_2_inter, file_i + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])+\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_2.csv\")\n",
    "                theodo_u.save_MC_interpolated_sorted(MC_3_inter, file_i + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])+\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_3.csv\")\n",
    "            else:\n",
    "                theodo_u.save_MC_interpolated_sorted(MC_1_inter, file_i + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])+\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_\"+str(rate_fake)+\"_1.csv\")\n",
    "                theodo_u.save_MC_interpolated_sorted(MC_2_inter, file_i + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])+\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_\"+str(rate_fake)+\"_2.csv\")\n",
    "                theodo_u.save_MC_interpolated_sorted(MC_3_inter, file_i + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])+\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_\"+str(rate_fake)+\"_3.csv\")\n",
    "\n",
    "        MC_1_sorted = []\n",
    "        MC_2_sorted = []\n",
    "        MC_3_sorted = []\n",
    "        if limit_taken_into_accout:\n",
    "            for i1,j1,k1 in zip(MC_1_inter,MC_2_inter,MC_3_inter):\n",
    "                d1 = abs(np.linalg.norm(i1[1]-j1[1])-extrinsic_calibration_results[0])\n",
    "                d2 = abs(np.linalg.norm(i1[1]-k1[1])-extrinsic_calibration_results[1])\n",
    "                d3 = abs(np.linalg.norm(k1[1]-j1[1])-extrinsic_calibration_results[2])\n",
    "                if d1<limit_dist and d2<limit_dist and d3<limit_dist:\n",
    "                    MC_1_sorted.append(i1)\n",
    "                    MC_2_sorted.append(j1)\n",
    "                    MC_3_sorted.append(k1)\n",
    "        else:\n",
    "            MC_1_sorted = MC_1_inter\n",
    "            MC_2_sorted = MC_2_inter\n",
    "            MC_3_sorted = MC_3_inter\n",
    "\n",
    "        if want_sensor_pose:\n",
    "            if Sensor!=\"Fake\":\n",
    "                P_sensor = theodo_g.chose_sensor_before_ptp(file_i, Sensor, Gps_reference_chosen)\n",
    "                Pose_sensor_MC = []\n",
    "                for i_mc,j_mc,k_mc in zip(MC_1_sorted,MC_2_sorted,MC_3_sorted):\n",
    "                    Pose_sensor = []\n",
    "                    p1_corrected = theodo_g.return_point_from_covariance(i_mc[2],i_mc[1], num_samples_MC_sensor)\n",
    "                    p2_corrected = theodo_g.return_point_from_covariance(j_mc[2],j_mc[1], num_samples_MC_sensor)\n",
    "                    p3_corrected = theodo_g.return_point_from_covariance(k_mc[2],k_mc[1], num_samples_MC_sensor)\n",
    "                    for i,j,k in zip(p1_corrected,p2_corrected,p3_corrected):\n",
    "                        Q = np.array([i, j, k]).T\n",
    "                        Q =np.concatenate((Q, np.array([[1,1,1]])), axis=0)\n",
    "                        T = theodo_u.point_to_point_minimization(P_sensor, Q)\n",
    "                        Pose_sensor.append(T)\n",
    "                    p_T, mu_T, cov_T = theodo_g.find_noise_list_tf(Pose_sensor)\n",
    "                    Pose_sensor_MC.append([i_mc[0],mu_T, cov_T])\n",
    "            else:\n",
    "                print(file_i, Sensor_fake, Gps_reference_chosen)\n",
    "                P_sensor = theodo_g.chose_sensor_before_ptp(file_i, Sensor_fake, Gps_reference_chosen)\n",
    "                Pose_sensor_MC = []\n",
    "                for i_mc,j_mc,k_mc in zip(MC_1_sorted,MC_2_sorted,MC_3_sorted):\n",
    "                    Pose_sensor = []\n",
    "                    p1_corrected = theodo_g.return_point_from_covariance(i_mc[2],i_mc[1], num_samples_MC_sensor)\n",
    "                    p2_corrected = theodo_g.return_point_from_covariance(j_mc[2],j_mc[1], num_samples_MC_sensor)\n",
    "                    p3_corrected = theodo_g.return_point_from_covariance(k_mc[2],k_mc[1], num_samples_MC_sensor)\n",
    "                    for i,j,k in zip(p1_corrected,p2_corrected,p3_corrected):\n",
    "                        Q = np.array([i, j, k]).T\n",
    "                        Q =np.concatenate((Q, np.array([[1,1,1]])), axis=0)\n",
    "                        T = theodo_u.point_to_point_minimization(P_sensor, Q)\n",
    "                        Pose_sensor.append(T)\n",
    "                    p_T, mu_T, cov_T = theodo_g.find_noise_list_tf(Pose_sensor)\n",
    "                    Pose_sensor_MC.append([i_mc[0],mu_T, cov_T])\n",
    "\n",
    "            if save_MC_sensor:\n",
    "                if Sensor==\"GNSS\":\n",
    "                    theodo_u.save_MC_interpolated_sorted(Pose_sensor_MC, file_i + \"uncertainty/sensor/\"+Sensor+\"_\"+str(Gps_reference_chosen)+\"_\"\n",
    "                                                         +str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])\n",
    "                                                     +\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\".csv\")\n",
    "                else:\n",
    "                    theodo_u.save_MC_interpolated_sorted(Pose_sensor_MC, file_i + \"uncertainty/sensor/\"+Sensor+\"_\"\n",
    "                                                         +str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])\n",
    "                                                     +\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\".csv\")\n",
    "\n",
    "        print(\"Interpolation finished !\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:45:20.983159169Z",
     "start_time": "2023-05-18T17:42:31.548797429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/20220307/sensors_extrinsic_calibration/sensor_positions.csv\n",
      "\n",
      "../data/20220307/sensors_extrinsic_calibration/sensor_positions.csv\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "theodo_g = importlib.reload(theodo_g)\n",
    "print(file_i + \"sensors_extrinsic_calibration/sensor_positions.csv\")\n",
    "print(theodo_g.chose_sensor_before_ptp(file_i, Sensor, Gps_reference_chosen))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:42:16.414017287Z",
     "start_time": "2023-05-18T17:42:16.370512916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:36:41.839213102Z",
     "start_time": "2023-05-18T17:36:41.661554018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
