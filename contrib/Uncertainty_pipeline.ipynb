{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scripts.prediction_utils as predict_u\n",
    "import scripts.theodolite_utils as theodo_u\n",
    "import scripts.theodolite_plot_function as theodo_p\n",
    "import scripts.groundtruth_utils as theodo_g\n",
    "import scripts.theodolite_function as theodo_f\n",
    "import time\n",
    "import torch\n",
    "from numpy import linalg\n",
    "import importlib\n",
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_p = importlib.reload(theodo_p)\n",
    "theodo_f = importlib.reload(theodo_f)\n",
    "predict_u = importlib.reload(predict_u)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/weather_2022/Quebec/data_sorted_2022.txt\n",
      "[1, 2, 1, 1, 3, 2]\n",
      "Number of data for theodolites: [4945 4681 4737]\n",
      "Bad measures: 558\n",
      "3836 3619 3690\n",
      "Number of sub-trajectories : 47\n",
      "Étape 0\n",
      "Number of input:  86\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  100.7\n",
      "Étape 1\n",
      "Number of input:  17\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  17.7\n",
      "Étape 2\n",
      "Number of input:  20\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  25.8\n",
      "Étape 3\n",
      "Number of input:  54\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  62.55\n",
      "Étape 4\n",
      "Number of input:  112\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  127.47\n",
      "Étape 5\n",
      "Number of input:  50\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  57.05\n",
      "Étape 6\n",
      "Number of input:  141\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  187.96\n",
      "Étape 7\n",
      "Number of input:  62\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  85.08\n",
      "Étape 8\n",
      "Number of input:  140\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  163.78\n",
      "Étape 9\n",
      "Number of input:  16\n",
      "Interpolation MC done !\n",
      "Exception extraction !\n",
      "Exception interpolation !\n",
      "Time :  11.02\n",
      "Étape 10\n",
      "Number of input:  284\n",
      "Interpolation MC done !\n",
      "Exception interpolation !\n",
      "Interpolation MC done !\n",
      "Time :  272.02\n",
      "Étape 11\n",
      "Number of input:  20\n",
      "Exception extraction !\n",
      "Interpolation MC done !\n",
      "Exception extraction !\n",
      "Time :  12.25\n",
      "Étape 12\n",
      "Number of input:  7\n",
      "Exception extraction !\n",
      "Interpolation MC done !\n",
      "Exception extraction !\n",
      "Time :  2.67\n",
      "Étape 13\n",
      "Number of input:  39\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  51.77\n",
      "Étape 14\n",
      "Number of input:  9\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Exception extraction !\n",
      "Time :  8.15\n",
      "Étape 15\n",
      "Number of input:  173\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Exception interpolation !\n",
      "Time :  187.02\n",
      "Étape 16\n",
      "Number of input:  6\n",
      "Exception extraction !\n",
      "Interpolation MC done !\n",
      "Exception interpolation !\n",
      "Time :  4.65\n",
      "Étape 17\n",
      "Number of input:  10\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  16.94\n",
      "Étape 18\n",
      "Number of input:  25\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  30.78\n",
      "Étape 19\n",
      "Number of input:  51\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  58.33\n",
      "Étape 20\n",
      "Number of input:  10\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  18.38\n",
      "Étape 21\n",
      "Number of input:  9\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  11.55\n",
      "Étape 22\n",
      "Number of input:  11\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  13.1\n",
      "Étape 23\n",
      "Number of input:  7\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  9.3\n",
      "Étape 24\n",
      "Number of input:  124\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  149.03\n",
      "Étape 25\n",
      "Number of input:  15\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  13.34\n",
      "Étape 26\n",
      "Number of input:  18\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  23.4\n",
      "Étape 27\n",
      "Number of input:  213\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  297.96\n",
      "Étape 28\n",
      "Number of input:  13\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  17.77\n",
      "Étape 29\n",
      "Number of input:  33\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  59.8\n",
      "Étape 30\n",
      "Number of input:  84\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  101.94\n",
      "Étape 31\n",
      "Number of input:  20\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  24.24\n",
      "Étape 32\n",
      "Number of input:  16\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  17.43\n",
      "Étape 33\n",
      "Number of input:  8\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Exception interpolation !\n",
      "Time :  12.5\n",
      "Étape 34\n",
      "Number of input:  33\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  37.92\n",
      "Étape 35\n",
      "Number of input:  115\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  150.05\n",
      "Étape 36\n",
      "Number of input:  59\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  75.32\n",
      "Étape 37\n",
      "Number of input:  182\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  234.05\n",
      "Étape 38\n",
      "Number of input:  15\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  18.32\n",
      "Étape 39\n",
      "Number of input:  102\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  139.01\n",
      "Étape 40\n",
      "Number of input:  10\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  11.42\n",
      "Étape 41\n",
      "Number of input:  27\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  33.02\n",
      "Étape 42\n",
      "Number of input:  23\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  25.04\n",
      "Étape 43\n",
      "Number of input:  114\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  156.4\n",
      "Étape 44\n",
      "Number of input:  9\n",
      "Exception extraction !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  7.93\n",
      "Étape 45\n",
      "Number of input:  362\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  409.16\n",
      "Étape 46\n",
      "Number of input:  360\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Interpolation MC done !\n",
      "Time :  416.4\n",
      "Conversion done !\n",
      "Conversion done !\n",
      "Conversion done !\n",
      "Interpolation finished !\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_p = importlib.reload(theodo_p)\n",
    "predict_u = importlib.reload(predict_u)\n",
    "theodo_g = importlib.reload(theodo_g)\n",
    "\n",
    "## Path of main files\n",
    "path = \"../data/20220224/\"\n",
    "\n",
    "# Reading sensor extrinsic calibration\n",
    "file_sensors = theodo_u.if_file_exist(path + \"sensors_extrinsic_calibration/calibration_results.csv\",'')\n",
    "extrinsic_calibration_results = theodo_u.read_extrinsic_calibration_results_file(file_sensors)\n",
    "\n",
    "# Reading sensor data\n",
    "# Sensor = \"Robosense_32\"\n",
    "Sensor = \"Fake\"   # GNSS or Robosense_32 or Fake\n",
    "# path_sensor_file = path+\"ICP/icp_odom.csv\"\n",
    "rate_fake = 20  # Hz\n",
    "Sensor_fake = \"GNSS\"\n",
    "\n",
    "# Sensor = \"GNSS\"\n",
    "path_sensor_file = path+\"gps_data/\"+\"gps3.txt\"\n",
    "path_sensor_file_synch_time = path+\"gps_data/delay_synchronization_GNSS_3.txt\"  # If applied to GNSS\n",
    "Gps_reference_chosen = 3    # 1: front, 2: back, 3: middle   # Only for GNSS\n",
    "\n",
    "## Parameters for pre-processing pipeline\n",
    "file = [\n",
    "        \"/home/maxime/data/ICRA_2023/Vaidis2022_dataset/20220224/20220224_inter_prism.bag\"\n",
    "]\n",
    "parameters = [\n",
    "    [1,2,1,1,3,2],  # 1. Apply filtering or not (Module 1), 2-3-4. Parameters tau_r, tau_a, tau_e (Module 1), 5. Parameter tau_s (Module 2), 6 Parameter tau_l (Module 4).\n",
    "]\n",
    "output = [\n",
    "        path\n",
    "]\n",
    "\n",
    "## Read sensor data which we want a ground truth\n",
    "sensor_data = []\n",
    "if Sensor == \"GNSS\":\n",
    "    GNSS_raw_data = theodo_u.read_prediction_data_Linear_csv_file(path_sensor_file)\n",
    "    time_delay = float(theodo_u.read_time_delay(path_sensor_file_synch_time))\n",
    "\n",
    "    for i in GNSS_raw_data:\n",
    "        raw_data = np.array([i[0] + time_delay, i[1], i[2], i[3], 0, 0, 0, 1])\n",
    "        sensor_data.append(raw_data)\n",
    "    sensor_data = np.array(sensor_data)\n",
    "\n",
    "if Sensor == \"Robosense_32\":\n",
    "    sensor_data = theodo_u.read_icp_odom_file(path_sensor_file)\n",
    "    sensor_data = np.array(sensor_data)\n",
    "\n",
    "# Limit acceptable for ground truth error\n",
    "limit_dist = 100  # Need to check the impact\n",
    "limit_uncertainty = 100 # Limit of eigenvalues taken into account\n",
    "\n",
    "## Range\n",
    "random_noise_range = [0, 0.004/2, 2]   ## Mean, sigma, ppm,  4mm + 2ppm (2 sigma)  ISO17123-3\n",
    "## Angles\n",
    "random_noise_angle = [0, 0.000024241/5*4/2]    # Mean, sigma, 5\"=0.000024241 precision datasheet  (2 sigma)  ISO17123-3\n",
    "## Tilt compensator\n",
    "random_noise_tilt = [0, 0.000002424/2]    # Mean, sigma, 0.5\"=0.000002424 precision datasheet  (2 sigma)  ISO17123-3\n",
    "## Weather\n",
    "weather_data_path = \"../data/weather_2022/Quebec/\"\n",
    "data_weather = np.array(theodo_u.read_weather_data(weather_data_path+\"data_sorted_2022.txt\"))\n",
    "\n",
    "## Number of rigid transforms to apply the uncertainty\n",
    "num_samples = 1000\n",
    "path_file_GCP = \"total_stations/GCP.txt\"\n",
    "frame_chosen, T_1_corrected, T_2_corrected, T_3_corrected = theodo_g.extrinsic_calibration_noise(path+path_file_GCP, random_noise_range, random_noise_angle, random_noise_tilt, num_samples)\n",
    "## Read Extrinsic results for RTS\n",
    "## Estimated extrinsic calibration uncertainty\n",
    "_, _, _, Tf_1, Tf_2, Tf_3 = theodo_u.read_marker_file(path+path_file_GCP, 1, 1)\n",
    "\n",
    "## Choice of noise model\n",
    "model_chosen = [1, 1, 1, 0, 0]  # Tilt noise, Atmospheric correction, extrinsic calibration, Weather corrections, Time synchronization # 1: Activate, 0:Disable\n",
    "\n",
    "save_MC_inteprolated = True\n",
    "num_samples_MC_sensor = 100\n",
    "want_sensor_pose = False\n",
    "save_MC_sensor = False\n",
    "\n",
    "for param in parameters:\n",
    "    print(param)\n",
    "\n",
    "    if param[0] == 0:\n",
    "        filtering = False\n",
    "    if param[0] == 1:\n",
    "        filtering = True\n",
    "    thresold_d = param[1]  ## tau_r [m/s]\n",
    "    thresold_a = param[2]  ## tau_a [deg/s]\n",
    "    thresold_e = param[3]  ## tau_e [deg/s]\n",
    "    limit_time_interval = param[4]  ## tau_s [s]\n",
    "    size_interval = param[5]    ## tau_l\n",
    "\n",
    "    Mode = \"STEAM\"  ## Interpolation choice: 1. L -> Linear interpolation, 2. SGP -> Gaussian Process with Stheno library, 3. STEAM\n",
    "    limit_search = limit_time_interval\n",
    "    save = False\n",
    "\n",
    "    save_index_1 = []\n",
    "    save_index_2 = []\n",
    "    save_index_3 = []\n",
    "\n",
    "    for fname, opath in zip(file, output):\n",
    "        if not filtering:\n",
    "            path_out = opath + \"raw_prediction/\"\n",
    "        else:\n",
    "            path_out = opath + \"filtered_prediction/\"\n",
    "\n",
    "        if filtering:\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(\n",
    "                fname)\n",
    "            index_1_f = theodo_u.thresold_raw_data(t1, d1, a1, e1, thresold_d, thresold_a * 3.1415926 / 180,\n",
    "                                                   thresold_e * 3.1415926 / 180, limit_time_interval)\n",
    "            index_2_f = theodo_u.thresold_raw_data(t2, d2, a2, e2, thresold_d, thresold_a * 3.1415926 / 180,\n",
    "                                                   thresold_e * 3.1415926 / 180, limit_time_interval)\n",
    "            index_3_f = theodo_u.thresold_raw_data(t3, d3, a3, e3, thresold_d, thresold_a * 3.1415926 / 180,\n",
    "                                                   thresold_e * 3.1415926 / 180, limit_time_interval)\n",
    "            t1 = t1[index_1_f]\n",
    "            t2 = t2[index_2_f]\n",
    "            t3 = t3[index_3_f]\n",
    "            tp1 = tp1[index_1_f].T\n",
    "            tp2 = tp2[index_2_f].T\n",
    "            tp3 = tp3[index_3_f].T\n",
    "            print(len(t1), len(t2), len(t3))\n",
    "        else:\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data(\n",
    "                fname)\n",
    "            print(len(t1), len(t2), len(t3))\n",
    "\n",
    "        list_interval, list_time = theodo_f.split_time_interval_all_data(t1, t2, t3, limit_time_interval)\n",
    "        list_trajectories_split = theodo_f.merge_interval(list_interval, list_time, t1, t2, t3, limit_search)\n",
    "\n",
    "        M_1_before_inter = []\n",
    "        M_2_before_inter = []\n",
    "        M_3_before_inter = []\n",
    "        Prediction_1 = []\n",
    "        Prediction_2 = []\n",
    "        Prediction_3 = []\n",
    "        T_prediction = []\n",
    "        Index_sensor = []\n",
    "\n",
    "        print(\"Number of sub-trajectories :\", len(list_trajectories_split))\n",
    "        number_ite = -1\n",
    "        for i in list_trajectories_split:\n",
    "            number_ite = number_ite + 1\n",
    "            print(\"Étape \" + str(number_ite))\n",
    "            index_1 = np.array([i[0, 0], i[1, 0]])\n",
    "            index_2 = np.array([i[0, 1], i[1, 1]])\n",
    "            index_3 = np.array([i[0, 2], i[1, 2]])\n",
    "\n",
    "            save_index_1.append(index_1)\n",
    "            save_index_2.append(index_2)\n",
    "            save_index_3.append(index_3)\n",
    "\n",
    "            begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])\n",
    "            end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])\n",
    "\n",
    "            if abs(end - begin) > size_interval and begin < end and number_ite<100:  # control number of sample\n",
    "\n",
    "                T_prediction_sensor = []\n",
    "                if Sensor!=\"Fake\":\n",
    "                    Number = 0\n",
    "                    for value_sensor_data in sensor_data:\n",
    "                        if end >= value_sensor_data[0] >= begin:\n",
    "                            T_prediction_sensor.append(value_sensor_data[0])\n",
    "                            Index_sensor.append(Number)\n",
    "                        Number = Number + 1\n",
    "\n",
    "                    T_prediction_init = torch.from_numpy(np.array(T_prediction_sensor))\n",
    "                else:\n",
    "                    List_time = np.arange(begin, end, 1/rate_fake)\n",
    "                    for i in List_time:\n",
    "                        T_prediction_sensor.append(i)\n",
    "                    T_prediction_init = torch.from_numpy(np.arange(begin, end, 1/rate_fake))\n",
    "\n",
    "                # Linear interpolation\n",
    "                if Mode == \"L\" or Mode == \"All\":\n",
    "\n",
    "                    ## Put trajectories in same frame\n",
    "                    tp1 = Tf_1 @ tp1\n",
    "                    tp2 = Tf_2 @ tp2\n",
    "                    tp3 = Tf_3 @ tp3\n",
    "\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = predict_u.data_training_L(t1, t2, t3,\n",
    "                                                                                      tp1, tp2, tp3,\n",
    "                                                                                      index_1,\n",
    "                                                                                      index_2,\n",
    "                                                                                      index_3)\n",
    "                    mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = predict_u.linear_interpolation(T1, X1, Y1,\n",
    "                                                                                        Z1, T2, X2,\n",
    "                                                                                        Y2, Z2, T3,\n",
    "                                                                                        X3, Y3, Z3)\n",
    "\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i)\n",
    "                        P1_L, P2_L, P3_L = predict_u.linear_prediction(i, 0, mx1, my1, mz1, mx2, my2, mz2,\n",
    "                                                                          mx3, my3, mz3)\n",
    "                        Prediction_1.append(P1_L)\n",
    "                        Prediction_2.append(P2_L)\n",
    "                        Prediction_3.append(P3_L)\n",
    "\n",
    "                if Mode == \"STEAM\" or Mode == \"All\":\n",
    "\n",
    "                    MC_1 = []\n",
    "                    MC_2 = []\n",
    "                    MC_3 = []\n",
    "                    tic = time.perf_counter()\n",
    "                    ## Compute uncertainty\n",
    "                    T1, D1, A1, E1 = predict_u.data_training_L_Raw_data(t1, d1, a1, e1, index_1)\n",
    "                    T2, D2, A2, E2 = predict_u.data_training_L_Raw_data(t2, d2, a2, e2, index_2)\n",
    "                    T3, D3, A3, E3 = predict_u.data_training_L_Raw_data(t3, d3, a3, e3, index_3)\n",
    "                    print(\"Number of input: \", len(T1))\n",
    "\n",
    "                    for i1,j1,k1,l1 in zip(T1,D1,A1,E1):\n",
    "                        mu_raw_data, _,cov_matrix_simulated = theodo_g.MC_raw_data(num_samples, j1, random_noise_range, k1, l1, random_noise_angle, random_noise_tilt, Tf_1, T_1_corrected, data_weather, i1, model_chosen)\n",
    "                        MC_1.append([i1,mu_raw_data,cov_matrix_simulated])\n",
    "                        M_1_before_inter.append([i1,mu_raw_data,cov_matrix_simulated])\n",
    "                    for i2,j2,k2,l2 in zip(T2,D2,A2,E2):\n",
    "                        mu_raw_data, _,cov_matrix_simulated = theodo_g.MC_raw_data(num_samples, j2, random_noise_range, k2, l2, random_noise_angle, random_noise_tilt, Tf_2, T_2_corrected, data_weather, i2, model_chosen)\n",
    "                        MC_2.append([i2,mu_raw_data,cov_matrix_simulated])\n",
    "                        M_2_before_inter.append([i2,mu_raw_data,cov_matrix_simulated])\n",
    "                    for i3,j3,k3,l3 in zip(T3,D3,A3,E3):\n",
    "                        mu_raw_data, _,cov_matrix_simulated = theodo_g.MC_raw_data(num_samples, j3, random_noise_range, k3, l3, random_noise_angle, random_noise_tilt, Tf_3, T_3_corrected, data_weather, i3, model_chosen)\n",
    "                        MC_3.append([i3,mu_raw_data,cov_matrix_simulated])\n",
    "                        M_3_before_inter.append([i3,mu_raw_data,cov_matrix_simulated])\n",
    "\n",
    "                    ## STEAM\n",
    "                    MC_1_interpolated = theodo_g.STEAM_interpolation_with_covariance(T1, T_prediction_sensor, MC_1)\n",
    "                    MC_2_interpolated = theodo_g.STEAM_interpolation_with_covariance(T2, T_prediction_sensor, MC_2)\n",
    "                    MC_3_interpolated = theodo_g.STEAM_interpolation_with_covariance(T3, T_prediction_sensor, MC_3)\n",
    "                    toc = time.perf_counter()\n",
    "                    print(\"Time : \", round(toc-tic,2))\n",
    "                    if(len(MC_1_interpolated)>0 and len(MC_2_interpolated)>0 and len(MC_3_interpolated)>0):\n",
    "                        Prediction_1.append(MC_1_interpolated)\n",
    "                        Prediction_2.append(MC_2_interpolated)\n",
    "                        Prediction_3.append(MC_3_interpolated)\n",
    "                        T_prediction.append(T_prediction_sensor)\n",
    "\n",
    "        MC_1_inter = []\n",
    "        MC_2_inter = []\n",
    "        MC_3_inter = []\n",
    "        for i1,j1,k1 in zip(Prediction_1,Prediction_2,Prediction_3):\n",
    "            for i2,j2,k2 in zip(i1,j1,k1):\n",
    "                # Check on uncertainty. If too high, remove triplet\n",
    "                eig1 = np.linalg.eigvals(i2[2])**0.5\n",
    "                eig2 = np.linalg.eigvals(j2[2])**0.5\n",
    "                eig3 = np.linalg.eigvals(k2[2])**0.5\n",
    "                if eig1[0]<limit_uncertainty and eig1[1]<limit_uncertainty and eig1[2]<limit_uncertainty \\\n",
    "                        and eig2[0]<limit_uncertainty and eig2[1]<limit_uncertainty and eig2[2]<limit_uncertainty \\\n",
    "                        and eig3[0]<limit_uncertainty and eig3[1]<limit_uncertainty and eig3[2]<limit_uncertainty:\n",
    "                    MC_1_inter.append(i2)\n",
    "                    MC_2_inter.append(j2)\n",
    "                    MC_3_inter.append(k2)\n",
    "\n",
    "        if save_MC_inteprolated:\n",
    "            theodo_u.save_MC_interpolated_sorted(MC_1_inter, path + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])\n",
    "                                                 +\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_1.csv\")\n",
    "            theodo_u.save_MC_interpolated_sorted(MC_2_inter, path + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])\n",
    "                                                 +\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_2.csv\")\n",
    "            theodo_u.save_MC_interpolated_sorted(MC_3_inter, path + \"uncertainty/interpolation/MC_\"+str(Sensor)+\"_\"+str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])\n",
    "                                                 +\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\"_3.csv\")\n",
    "\n",
    "        MC_1_sorted = []\n",
    "        MC_2_sorted = []\n",
    "        MC_3_sorted = []\n",
    "        for i1,j1,k1 in zip(MC_1_inter,MC_2_inter,MC_3_inter):\n",
    "            d1 = abs(np.linalg.norm(i1[1]-j1[1])-extrinsic_calibration_results[0])\n",
    "            d2 = abs(np.linalg.norm(i1[1]-k1[1])-extrinsic_calibration_results[1])\n",
    "            d3 = abs(np.linalg.norm(k1[1]-j1[1])-extrinsic_calibration_results[2])\n",
    "            if d1<limit_dist and d2<limit_dist and d3<limit_dist:\n",
    "                MC_1_sorted.append(i1)\n",
    "                MC_2_sorted.append(j1)\n",
    "                MC_3_sorted.append(k1)\n",
    "\n",
    "        if want_sensor_pose==True:\n",
    "            if Sensor!=\"Fake\":\n",
    "                P_sensor = theodo_g.chose_sensor_before_ptp(path, Sensor, Gps_reference_chosen)\n",
    "                Pose_sensor_MC = []\n",
    "                for i_mc,j_mc,k_mc in zip(MC_1_sorted,MC_2_sorted,MC_3_sorted):\n",
    "                    Pose_sensor = []\n",
    "                    p1_corrected = theodo_g.return_point_from_covariance(i_mc[2],i_mc[1], num_samples_MC_sensor)\n",
    "                    p2_corrected = theodo_g.return_point_from_covariance(j_mc[2],j_mc[1], num_samples_MC_sensor)\n",
    "                    p3_corrected = theodo_g.return_point_from_covariance(k_mc[2],k_mc[1], num_samples_MC_sensor)\n",
    "                    for i,j,k in zip(p1_corrected,p2_corrected,p3_corrected):\n",
    "                        Q = np.array([i, j, k]).T\n",
    "                        Q =np.concatenate((Q, np.array([[1,1,1]])), axis=0)\n",
    "                        T = theodo_u.point_to_point_minimization(P_sensor, Q)\n",
    "                        Pose_sensor.append(T)\n",
    "                    p_T, mu_T, cov_T = theodo_g.find_noise_list_tf(Pose_sensor)\n",
    "                    Pose_sensor_MC.append([i_mc[0],mu_T, cov_T])\n",
    "            else:\n",
    "                P_sensor = theodo_g.chose_sensor_before_ptp(path, Sensor_fake, Gps_reference_chosen)\n",
    "                Pose_sensor_MC = []\n",
    "                for i_mc,j_mc,k_mc in zip(MC_1_sorted,MC_2_sorted,MC_3_sorted):\n",
    "                    Pose_sensor = []\n",
    "                    p1_corrected = theodo_g.return_point_from_covariance(i_mc[2],i_mc[1], num_samples_MC_sensor)\n",
    "                    p2_corrected = theodo_g.return_point_from_covariance(j_mc[2],j_mc[1], num_samples_MC_sensor)\n",
    "                    p3_corrected = theodo_g.return_point_from_covariance(k_mc[2],k_mc[1], num_samples_MC_sensor)\n",
    "                    for i,j,k in zip(p1_corrected,p2_corrected,p3_corrected):\n",
    "                        Q = np.array([i, j, k]).T\n",
    "                        Q =np.concatenate((Q, np.array([[1,1,1]])), axis=0)\n",
    "                        T = theodo_u.point_to_point_minimization(P_sensor, Q)\n",
    "                        Pose_sensor.append(T)\n",
    "                    p_T, mu_T, cov_T = theodo_g.find_noise_list_tf(Pose_sensor)\n",
    "                    Pose_sensor_MC.append([i_mc[0],mu_T, cov_T])\n",
    "\n",
    "            if save_MC_sensor:\n",
    "                if Sensor==\"GNSS\":\n",
    "                    theodo_u.save_MC_interpolated_sorted(Pose_sensor_MC, path + \"uncertainty/sensor/\"+Sensor+\"_\"+str(Gps_reference_chosen)+\"_\"\n",
    "                                                         +str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])\n",
    "                                                     +\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\".csv\")\n",
    "                else:\n",
    "                    theodo_u.save_MC_interpolated_sorted(Pose_sensor_MC, path + \"uncertainty/sensor/\"+Sensor+\"_\"\n",
    "                                                         +str(model_chosen[0])+\"_\"+str(model_chosen[1])+\"_\"+str(model_chosen[2])\n",
    "                                                     +\"_\"+str(model_chosen[3])+\"_\"+str(model_chosen[4])+\".csv\")\n",
    "\n",
    "        print(\"Interpolation finished !\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_g = importlib.reload(theodo_g)\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "for i in M_2_before_inter:\n",
    "    theodo_g.plot_ellipse(plt.gca(), i[1][0:2], i[2][0:2,0:2], n_std=1, color=\"red\")\n",
    "    plt.scatter(i[1][0], i[1][1], s=2, color='r')\n",
    "for i in MC_2_inter[0:-1]:\n",
    "    theodo_g.plot_ellipse(plt.gca(), i[1][0:2], i[2][0:2,0:2], n_std=1, color=\"green\")\n",
    "    plt.scatter(i[1][0], i[1][1], s=2, color='green')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_g = importlib.reload(theodo_g)\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "for i in M_1_before_inter:\n",
    "    theodo_g.plot_ellipse(plt.gca(), i[1][1:3], i[2][1:3,1:3], n_std=1, color=\"red\")\n",
    "    plt.scatter(i[1][1], i[1][2], s=2, color='r')\n",
    "for i in MC_1_inter[0:-1]:\n",
    "    theodo_g.plot_ellipse(plt.gca(), i[1][1:3], i[2][1:3,1:3], n_std=1, color=\"green\")\n",
    "    plt.scatter(i[1][1], i[1][2], s=2, color='green')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timestamp = []\n",
    "Coordinates = []\n",
    "Covariance = []\n",
    "for i in MC_1_sorted:\n",
    "    timestamp.append(i[0])\n",
    "    Coordinates.append(i[1][0:3])\n",
    "    cov = i[2][0:3,0:3]\n",
    "    w, v = np.linalg.eig(cov)\n",
    "    Covariance.append(w)\n",
    "timestamp = np.array(timestamp)\n",
    "Coordinates = np.array(Coordinates)\n",
    "Covariance = np.array(Covariance)\n",
    "\n",
    "tp1c = (Tf_1@tp1).T\n",
    "tp2c = (Tf_2@tp2).T\n",
    "tp3c = (Tf_3@tp3).T\n",
    "\n",
    "tp1c = tp1.T\n",
    "tp2c = tp2.T\n",
    "tp3c = tp3.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "tp_data = tp1c\n",
    "t_data = t1\n",
    "std_n = 10\n",
    "limit = 300\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(6, 6))\n",
    "ax1.scatter(t_data[:limit], tp_data[:limit,0], color='black', s=2)\n",
    "ax1.scatter(timestamp, Coordinates[:,0], color='green', s=2)\n",
    "ax1.fill_between(timestamp, Coordinates[:,0]-std_n*Covariance[:,0], Coordinates[:,0]+std_n*Covariance[:,0], color=\"green\", alpha=0.3)\n",
    "ax2.scatter(t_data[:limit], tp_data[:limit,1], color='black', s=2)\n",
    "ax2.scatter(timestamp, Coordinates[:,1], color='red', s=2)\n",
    "ax2.fill_between(timestamp, Coordinates[:,1]-std_n*Covariance[:,1], Coordinates[:,1]+std_n*Covariance[:,1], color=\"red\", alpha=0.3)\n",
    "ax3.scatter(t_data[:limit], tp_data[:limit,2], color='black', s=2)\n",
    "ax3.scatter(timestamp, Coordinates[:,2], color='blue', s=2)\n",
    "ax3.fill_between(timestamp, Coordinates[:,2]-std_n*Covariance[:,2], Coordinates[:,2]+std_n*Covariance[:,2], color=\"blue\", alpha=0.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "theodo_g = importlib.reload(theodo_g)\n",
    "\n",
    "# Setup the plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "for info in MC_1_sorted:\n",
    "    mu1= info[1]\n",
    "    cov1 = info[2][0:3,0:3]\n",
    "    s1 = np.random.multivariate_normal(mu1, cov1, (200))\n",
    "    nstd = 2    # 95% confidence interval\n",
    "    mu1_ = np.mean(s1, axis=0)\n",
    "    cov1_ = np.cov(s1.T)\n",
    "    X1,Y1,Z1 = theodo_g.get_cov_ellipsoid_bis(cov1_, mu1_, nstd)\n",
    "    ax.plot_wireframe(X1,Y1,Z1, color='r', alpha=0.1)\n",
    "for info in MC_2_sorted:\n",
    "    mu1= info[1]\n",
    "    cov1 = info[2][0:3,0:3]\n",
    "    s1 = np.random.multivariate_normal(mu1, cov1, (200))\n",
    "    nstd = 2    # 95% confidence interval\n",
    "    mu1_ = np.mean(s1, axis=0)\n",
    "    cov1_ = np.cov(s1.T)\n",
    "    X1,Y1,Z1 = theodo_g.get_cov_ellipsoid_bis(cov1_, mu1_, nstd)\n",
    "    ax.plot_wireframe(X1,Y1,Z1, color='green', alpha=0.1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "\n",
    "path_vtk = \"/home/maxime/data/vtk_traj/20220224/\"\n",
    "sigma_plot = 10\n",
    "theodo_u.save_to_VTK_uncertainty(sigma_plot, MC_1_sorted, path_vtk + \"Prisme_1.vtk\")\n",
    "theodo_u.save_to_VTK_uncertainty(sigma_plot, MC_2_sorted, path_vtk + \"Prisme_2.vtk\")\n",
    "theodo_u.save_to_VTK_uncertainty(sigma_plot, MC_3_sorted, path_vtk + \"Prisme_3.vtk\")\n",
    "theodo_u.save_to_VTK_uncertainty(sigma_plot, Pose_sensor_MC, path_vtk + \"Sensor.vtk\")\n",
    "print(\"Done !\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Mu_1 = MC_1_sorted[2][1]\n",
    "Mu_2 = MC_1_sorted[1][1]\n",
    "C1 = MC_1_sorted[2][2]\n",
    "C2 = MC_1_sorted[1][2]\n",
    "print(Mu_1)\n",
    "print(Mu_2)\n",
    "print(C1)\n",
    "print(C2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "# Bhattacharyya distance, measures the similarity of two probability distributions, not a metric\n",
    "print(theodo_u.Bhattacharyya_distance(Mu_1, Mu_2, C1, C2))\n",
    "# Hellinger distance, quantify the similarity between two probability distributions, bounded metric ([0,1])\n",
    "print(theodo_u.Hellinger_distance_square(Mu_1, Mu_2, C1, C2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
