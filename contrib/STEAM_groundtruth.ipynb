{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [9], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtheodolite_utils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtheodo_u\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtheodolite_function\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtheodo_f\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprediction_utils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mprediction_u\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'scripts'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import importlib\n",
    "import scripts.theodolite_utils as theodo_u\n",
    "import scripts.theodolite_function as theodo_f\n",
    "import scripts.prediction_utils as prediction_u\n",
    "import scripts.resection_functions as theodo_r\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(6, suppress=True)\n",
    "\n",
    "from pylgmath import Transformation, se3op\n",
    "from pysteam.trajectory import Time\n",
    "from pysteam.trajectory.const_vel import Interface as TrajectoryInterface\n",
    "from pysteam.problem import OptimizationProblem, StaticNoiseModel, L2LossFunc, WeightedLeastSquareCostTerm\n",
    "from pysteam.solver import GaussNewtonSolver, DoglegGaussNewtonSolver\n",
    "from pysteam.evaluable import vspace as vspaceev, se3 as se3ev\n",
    "from pysteam.evaluable.se3 import SE3StateVar\n",
    "from pysteam.evaluable.vspace import VSpaceStateVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "\n",
    "# Path of the RTS data\n",
    "path = \"../data/20220224/\"\n",
    "\n",
    "# Read Extrinsic results for RTS\n",
    "Tf = theodo_u.read_saved_tf(path+\"list_tf/TF_list_static_cp.csv\")\n",
    "#Tf = theodo_u.read_saved_tf(path+\"list_tf/TF_list_linear_dynamic_4dof.csv\")\n",
    "Tf_1 = Tf[0]\n",
    "Tf_12 = Tf[1]\n",
    "Tf_13 = Tf[2]\n",
    "\n",
    "# Reading sensor data\n",
    "Sensor = \"GNSS\"   # GNSS or Robosense_32\n",
    "# path_sensor_file = path+\"ICP/icp_odom.csv\"\n",
    "\n",
    "# Sensor = \"GNSS\"\n",
    "path_sensor_file = path+\"gps_data/\"+\"gpsmiddle.txt\"\n",
    "path_sensor_file_synch_time = path+\"gps_data/delay_synchronization_GNSS_3.txt\"  # If applied to GNSS\n",
    "Gps_reference_chosen = 3    # 1: front, 2: back, 3: middle   # Only for GNSS\n",
    "\n",
    "if Sensor == \"GNSS\":\n",
    "    GNSS_raw_data = theodo_u.read_prediction_data_Linear_csv_file(path_sensor_file)\n",
    "    time_delay = float(theodo_u.read_time_delay(path_sensor_file_synch_time))\n",
    "    sensor_data = []\n",
    "    for i in GNSS_raw_data:\n",
    "        raw_data = np.array([i[0]+time_delay, i[1], i[2], i[3], 0, 0, 0, 1])\n",
    "        sensor_data.append(raw_data)\n",
    "    sensor_data = np.array(sensor_data)\n",
    "if Sensor==\"Robosense_32\":\n",
    "    sensor_data = theodo_u.read_icp_odom_file(path_sensor_file)\n",
    "    sensor_data = np.array(sensor_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Path of the rosbags to process the RTS data\n",
    "file = [\n",
    "        \"/home/maxime/data/ICRA_2023/Vaidis2022_dataset/20220224/20220224_inter_prism.bag\"\n",
    "       ]\n",
    "\n",
    "# Parameters to select:\n",
    "# 1. Apply filtering or not (Module 1)\n",
    "# 2-3-4. Parameters tau_r, tau_a, tau_e (Module 1)\n",
    "# 5. Parameter tau_s (Module 2)\n",
    "\n",
    "parameters = [\n",
    "    [1,2,2,2,4],\n",
    "]\n",
    "\n",
    "# Path of output\n",
    "output = [\n",
    "        path\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_f = importlib.reload(theodo_f)\n",
    "prediction_u = importlib.reload(prediction_u)\n",
    "\n",
    "for param in parameters:\n",
    "    print(param)\n",
    "\n",
    "    if(param[0]==0):\n",
    "        filtering = False\n",
    "    if(param[0]==1):\n",
    "        filtering = True\n",
    "    thresold_d = param[1]                # tau_r [m/s]\n",
    "    thresold_a = param[2]                # tau_a [deg/s]\n",
    "    thresold_e = param[3]                # tau_e [deg/s]\n",
    "    limit_time_interval = param[4]       # tau_s [s]\n",
    "    size_interval = 2\n",
    "\n",
    "    Mode = \"L\"       # Interpolation choice: 1. L -> Linear interpolation, 2. SGP -> Gaussian Process with Stheno library\n",
    "    limit_search = limit_time_interval\n",
    "    save = False\n",
    "\n",
    "    save_index_1 = []\n",
    "    save_index_2 = []\n",
    "    save_index_3 = []\n",
    "\n",
    "    for fname, opath in zip(file,output):\n",
    "        if(not filtering):\n",
    "            path_out = opath + \"raw_prediction/\"\n",
    "        else:\n",
    "            path_out = opath + \"filtered_prediction/\"\n",
    "\n",
    "        if(filtering):\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(fname)\n",
    "            index_1_f = theodo_u.thresold_raw_data(t1, d1, a1, e1, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_2_f = theodo_u.thresold_raw_data(t2, d2, a2, e2, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_3_f = theodo_u.thresold_raw_data(t3, d3, a3, e3, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            t1 = t1[index_1_f]\n",
    "            t2 = t2[index_2_f]\n",
    "            t3 = t3[index_3_f]\n",
    "            tp1 = tp1[index_1_f].T\n",
    "            tp2 = tp2[index_2_f].T\n",
    "            tp3 = tp3[index_3_f].T\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "        else:\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data(fname)\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Put trajectories in same frame\n",
    "        tp1 = Tf_1@tp1\n",
    "        tp2 = Tf_12@tp2\n",
    "        tp3 = Tf_13@tp3\n",
    "\n",
    "        list_interval, list_time = theodo_f.split_time_interval_all_data(t1, t2, t3, limit_time_interval)\n",
    "        list_trajectories_split = theodo_f.merge_interval(list_interval, list_time, t1, t2, t3, limit_search)\n",
    "\n",
    "        Prediction_1 = []\n",
    "        Prediction_2 = []\n",
    "        Prediction_3 = []\n",
    "        T_prediction = []\n",
    "        Index_sensor = []\n",
    "\n",
    "        for i in tqdm(list_trajectories_split):\n",
    "\n",
    "            index_1 = np.array([i[0,0],i[1,0]])\n",
    "            index_2 = np.array([i[0,1],i[1,1]])\n",
    "            index_3 = np.array([i[0,2],i[1,2]])\n",
    "\n",
    "            save_index_1.append(index_1)\n",
    "            save_index_2.append(index_2)\n",
    "            save_index_3.append(index_3)\n",
    "\n",
    "            begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])\n",
    "            end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])\n",
    "\n",
    "            if abs(end-begin)>size_interval and begin<end:\n",
    "\n",
    "                Number = 0\n",
    "                T_prediction_sensor = []\n",
    "                for value_sensor_data in sensor_data:\n",
    "                    if end >= value_sensor_data[0] >= begin:\n",
    "                        T_prediction_sensor.append(value_sensor_data[0])\n",
    "                        Index_sensor.append(Number)\n",
    "                    Number = Number + 1\n",
    "\n",
    "                #rate = 10  #Hz\n",
    "                #T_prediction_init = torch.from_numpy(np.arange(begin, end, 1/rate))\n",
    "                #print(T_prediction_sensor)\n",
    "                T_prediction_init = torch.from_numpy(np.array(T_prediction_sensor))\n",
    "\n",
    "                # Linear interpolation\n",
    "                if Mode == \"L\" or Mode == \"All\":\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = prediction_u.data_training_L(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = prediction_u.linear_interpolation(T1, X1, Y1, Z1, T2, X2, Y2, Z2,T3, X3, Y3, Z3)\n",
    "\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i)\n",
    "                        P1_L, P2_L, P3_L = prediction_u.linear_prediction(i, 0, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                        Prediction_1.append(P1_L)\n",
    "                        Prediction_2.append(P2_L)\n",
    "                        Prediction_3.append(P3_L)\n",
    "\n",
    "        stop_time = time.time()\n",
    "        print(stop_time - start_time)\n",
    "\n",
    "        print(\"Interpolation finished !\")\n",
    "\n",
    "        if save:\n",
    "\n",
    "            if(Mode == \"L\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+\"-L\"\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+\"-L\"\n",
    "\n",
    "                if save:\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_1, path_out+trajectoire+ \"_1.csv\")\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_2, path_out+trajectoire+ \"_2.csv\")\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_3, path_out+trajectoire+ \"_3.csv\")\n",
    "\n",
    "            print(\"Saved !\")\n",
    "\n",
    "# Trajectories predicted\n",
    "Time_p = np.array(T_prediction)\n",
    "P1_arr = np.array(Prediction_1)\n",
    "P2_arr = np.array(Prediction_2)\n",
    "P3_arr = np.array(Prediction_3)\n",
    "Index_sensor = np.array(Index_sensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_r = importlib.reload(theodo_r)\n",
    "file_sensors = theodo_u.if_file_exist(path + \"sensors_extrinsic_calibration/calibration_results.csv\",'')\n",
    "extrinsic_calibration_results = theodo_u.read_extrinsic_calibration_results_file(file_sensors)\n",
    "error=[]\n",
    "error = theodo_r.inter_prism_distance_error_mean(P1_arr, P2_arr, P3_arr, extrinsic_calibration_results[0:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Outliers for results\n",
    "P1_sort = []\n",
    "P2_sort = []\n",
    "P3_sort = []\n",
    "Time_sort = []\n",
    "Index_sensor_sort = []\n",
    "threshold_inter_prims_error = 10    # In mm, need to check how to choose it\n",
    "for i,j,k,l,m,n in zip(error,P1_arr,P2_arr,P3_arr,T_prediction,Index_sensor):\n",
    "    if i<threshold_inter_prims_error:\n",
    "        P1_sort.append(j)\n",
    "        P2_sort.append(k)\n",
    "        P3_sort.append(l)\n",
    "        Time_sort.append(m)\n",
    "        Index_sensor_sort.append(n)\n",
    "print(\"Number points input/output: \", len(P1_arr), len(P1_sort))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load sensor positions\n",
    "file_sensor_positions = theodo_u.if_file_exist(path + \"sensors_extrinsic_calibration/sensor_positions.csv\",'')\n",
    "sensor_positions_list = theodo_u.read_extrinsic_calibration_results_file(file_sensor_positions)\n",
    "\n",
    "Sensors = []\n",
    "P1_position_RTS = np.array(sensor_positions_list[0])\n",
    "P2_position_RTS = np.array(sensor_positions_list[1])\n",
    "P3_position_RTS = np.array(sensor_positions_list[2])\n",
    "if Sensor==\"GNSS\":\n",
    "    Sensors.append(np.array(sensor_positions_list[3]))\n",
    "    Sensors.append(np.array(sensor_positions_list[4]))\n",
    "    Sensors.append(np.array(sensor_positions_list[5]))\n",
    "\n",
    "    P1_position_GNSS = P1_position_RTS - Sensors[Gps_reference_chosen-1]\n",
    "    P1_position_GNSS[3] = 1\n",
    "    P2_position_GNSS = P2_position_RTS - Sensors[Gps_reference_chosen-1]\n",
    "    P2_position_GNSS[3] = 1\n",
    "    P3_position_GNSS = P3_position_RTS - Sensors[Gps_reference_chosen-1]\n",
    "    P3_position_GNSS[3] = 1\n",
    "\n",
    "    P_sensor = np.array([P1_position_GNSS,\n",
    "                P2_position_GNSS,\n",
    "                P3_position_GNSS]).T\n",
    "\n",
    "if Sensor==\"Robosense_32\":\n",
    "    Sensors.append(np.array(sensor_positions_list[6]))\n",
    "    Sensors.append(np.array(sensor_positions_list[7]))\n",
    "    Sensors.append(np.array(sensor_positions_list[8]))\n",
    "    Sensors.append(np.array(sensor_positions_list[9]))\n",
    "    ux = Sensors[1] - Sensors[0]\n",
    "    uy = Sensors[2] - Sensors[0]\n",
    "    uz = Sensors[3] - Sensors[0]\n",
    "\n",
    "    T_lidar = np.array([[ux[0],uy[0],uz[0],Sensors[0][0]],\n",
    "                        [ux[1],uy[1],uz[1],Sensors[0][1]],\n",
    "                        [ux[2],uy[2],uz[2],Sensors[0][2]],\n",
    "                        [0,0,0,1]])\n",
    "    T_lidar_inv = np.linalg.inv(T_lidar)\n",
    "    P1_position_lidar = T_lidar_inv@P1_position_RTS\n",
    "    P2_position_lidar = T_lidar_inv@P2_position_RTS\n",
    "    P3_position_lidar = T_lidar_inv@P3_position_RTS\n",
    "\n",
    "    P_sensor = np.array([P1_position_lidar,\n",
    "                P2_position_lidar,\n",
    "                P3_position_lidar]).T\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Doing a minimization between these not moving points, and the 3D prism coordinates\n",
    "# Pose_GNSS is a list of each rigid transform founded\n",
    "list_sensor_time = []\n",
    "Pose_sensor = []\n",
    "Prism_corrected = []\n",
    "number = len(P1_sort)\n",
    "for i in range(0,number):\n",
    "    Q = np.array([P1_sort[i], P2_sort[i], P3_sort[i]]).T\n",
    "    Q =np.concatenate((Q, np.array([[1,1,1]])), axis=0)\n",
    "    T = theodo_u.point_to_point_minimization(P_sensor, Q)\n",
    "    Pose_sensor.append(T)\n",
    "    prism_correct = T@P_sensor\n",
    "    Prism_corrected.append(prism_correct)\n",
    "    list_sensor_time.append(Time_sort[i])\n",
    "Pose_sensor_arr = np.array(Pose_sensor)\n",
    "Prism_corrected_arr = np.array(Prism_corrected)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_f = importlib.reload(theodo_f)\n",
    "prediction_u = importlib.reload(prediction_u)\n",
    "\n",
    "for param in parameters:\n",
    "    print(param)\n",
    "\n",
    "    if(param[0]==0):\n",
    "        filtering = False\n",
    "    if(param[0]==1):\n",
    "        filtering = True\n",
    "    thresold_d = param[1]                # tau_r [m/s]\n",
    "    thresold_a = param[2]                # tau_a [deg/s]\n",
    "    thresold_e = param[3]                # tau_e [deg/s]\n",
    "    limit_time_interval = param[4]       # tau_s [s]\n",
    "    size_interval = 2\n",
    "\n",
    "    Mode = \"L\"       # Interpolation choice: 1. L -> Linear interpolation, 2. SGP -> Gaussian Process with Stheno library\n",
    "    limit_search = limit_time_interval\n",
    "    save = False\n",
    "\n",
    "    save_index_1 = []\n",
    "    save_index_2 = []\n",
    "    save_index_3 = []\n",
    "\n",
    "    for fname, opath in zip(file,output):\n",
    "        if(not filtering):\n",
    "            path_out = opath + \"raw_prediction/\"\n",
    "        else:\n",
    "            path_out = opath + \"filtered_prediction/\"\n",
    "\n",
    "        if(filtering):\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(fname)\n",
    "            index_1_f = theodo_u.thresold_raw_data(t1, d1, a1, e1, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_2_f = theodo_u.thresold_raw_data(t2, d2, a2, e2, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_3_f = theodo_u.thresold_raw_data(t3, d3, a3, e3, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            t1 = t1[index_1_f]\n",
    "            t2 = t2[index_2_f]\n",
    "            t3 = t3[index_3_f]\n",
    "            tp1 = tp1[index_1_f].T\n",
    "            tp2 = tp2[index_2_f].T\n",
    "            tp3 = tp3[index_3_f].T\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "        else:\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data(fname)\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "\n",
    "        T_measure = np.concatenate([t1, t2, t3])\n",
    "        print(len(t1), len(t2), len(t3))\n",
    "        print(len(T_measure))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Put trajectories in same frame\n",
    "        tp1 = Tf_1@tp1\n",
    "        tp2 = Tf_12@tp2\n",
    "        tp3 = Tf_13@tp3\n",
    "\n",
    "        list_interval, list_time = theodo_f.split_time_interval_all_data(t1, t2, t3, limit_time_interval)\n",
    "        list_trajectories_split = theodo_f.merge_interval(list_interval, list_time, t1, t2, t3, limit_search)\n",
    "\n",
    "        Prediction_1 = []\n",
    "        Prediction_2 = []\n",
    "        Prediction_3 = []\n",
    "        T_prediction = []\n",
    "        Index_sensor = []\n",
    "\n",
    "        for i in tqdm(list_trajectories_split):\n",
    "\n",
    "            index_1 = np.array([i[0,0],i[1,0]])\n",
    "            index_2 = np.array([i[0,1],i[1,1]])\n",
    "            index_3 = np.array([i[0,2],i[1,2]])\n",
    "\n",
    "            save_index_1.append(index_1)\n",
    "            save_index_2.append(index_2)\n",
    "            save_index_3.append(index_3)\n",
    "\n",
    "            begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])\n",
    "            end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])\n",
    "\n",
    "            if abs(end-begin)>size_interval and begin<end:\n",
    "\n",
    "                Number = 0\n",
    "                T_prediction_sensor = []\n",
    "                for value_sensor_data in sensor_data:\n",
    "                    if end >= value_sensor_data[0] >= begin:\n",
    "                        T_prediction_sensor.append(value_sensor_data[0])\n",
    "                        Index_sensor.append(Number)\n",
    "                    Number = Number + 1\n",
    "\n",
    "                #rate = 10  #Hz\n",
    "                #T_prediction_init = torch.from_numpy(np.arange(begin, end, 1/rate))\n",
    "                #print(T_prediction_sensor)\n",
    "                T_prediction_init = torch.from_numpy(np.array(T_prediction_sensor))\n",
    "\n",
    "                # Linear interpolation\n",
    "                if Mode == \"L\" or Mode == \"All\":\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = prediction_u.data_training_L(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = prediction_u.linear_interpolation(T1, X1, Y1, Z1, T2, X2, Y2, Z2,T3, X3, Y3, Z3)\n",
    "\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i)\n",
    "                        P1_L, P2_L, P3_L = prediction_u.linear_prediction(i, 0, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                        Prediction_1.append(P1_L)\n",
    "                        Prediction_2.append(P2_L)\n",
    "                        Prediction_3.append(P3_L)\n",
    "\n",
    "        stop_time = time.time()\n",
    "        print(stop_time - start_time)\n",
    "\n",
    "        print(\"Interpolation finished !\")\n",
    "\n",
    "        if save:\n",
    "\n",
    "            if(Mode == \"L\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+\"-L\"\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+\"-L\"\n",
    "\n",
    "                if save:\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_1, path_out+trajectoire+ \"_1.csv\")\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_2, path_out+trajectoire+ \"_2.csv\")\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_3, path_out+trajectoire+ \"_3.csv\")\n",
    "\n",
    "            print(\"Saved !\")\n",
    "\n",
    "# Trajectories predicted\n",
    "Time_p = np.array(T_prediction)\n",
    "P1_arr = np.array(Prediction_1)\n",
    "P2_arr = np.array(Prediction_2)\n",
    "P3_arr = np.array(Prediction_3)\n",
    "Index_sensor = np.array(Index_sensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STEAM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(Pose_sensor_arr))\n",
    "print(len(Time_sort))\n",
    "\n",
    "before = Time_sort[0]\n",
    "index_gap = []\n",
    "index = 0\n",
    "index_init = 0\n",
    "for i in Time_sort:\n",
    "    if(abs(i-before)>4):\n",
    "        index_gap.append([index_init,index-1])\n",
    "        index_init = index\n",
    "    before = i\n",
    "    index = index + 1\n",
    "index_gap.append([index_init,index-1])\n",
    "# print(Time_sort[index_gap[0]-1], Time_sort[index_gap[0]])\n",
    "print(index_gap[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_u.read_rosbag_imu_node(\"/home/maxime/data/ICRA_2023/Vaidis2022_dataset/20220224/20220224_inter_prism/\", True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Qc\n",
    "qcd = np.ones(6)\n",
    "## states\n",
    "states = []\n",
    "for i in range(index_gap[0][0], index_gap[0][1]+1):\n",
    "    states.append([Time_sort[i], Transformation(T_ba=Pose_sensor_arr[i]), np.zeros((6, 1))])\n",
    "state_vars = [(t, SE3StateVar(T_vi), VSpaceStateVar(w_iv_inv)) for t, T_vi, w_iv_inv in states]\n",
    "state_vars[0][1].locked = True  # lock first pose\n",
    "state_vars[0][2].locked = True  # lock first velocity\n",
    "state_vars[-1][1].locked = True  # lock last pose\n",
    "state_vars[-1][2].locked = True  # lock last velocity\n",
    "\n",
    "## pose measurements\n",
    "T_iv_noise = np.diag([1e-3, 1e-3, 1e-3, 1e-3, 1e-3, 1e-3])\n",
    "T_iv_meas = []\n",
    "T_iv_meas.append((1.0 * T_TOTAL, Transformation(xi_ab=np.array([[0.2, 0.05, 0.15, -0.1, -0.8, 0.6]]).T)))\n",
    "## velocity measurements\n",
    "w_iv_inv_noise = np.diag([1e0, 1e0, 1e0, 1e0, 1e0, 1e0])\n",
    "w_iv_inv_meas = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traj = TrajectoryInterface(qcd=qcd)\n",
    "for t_l, T_vi, w_iv_inv in state_vars:\n",
    "    traj.add_knot(time=Time(t_l), T_k0=T_vi, w_0k_ink=w_iv_inv)\n",
    "#\n",
    "cost_terms = []\n",
    "loss_func = L2LossFunc()\n",
    "# pose measurements -> cost terms\n",
    "noise_model = StaticNoiseModel(T_iv_noise)\n",
    "for t_l, T_iv in T_iv_meas:\n",
    "    intp_pos = traj.get_pose_interpolator(Time(secs=t_l))\n",
    "    error_func = se3ev.tran2vec(se3ev.compose(intp_pos, SE3StateVar(T_iv, locked=True)))\n",
    "    cost_term = WeightedLeastSquareCostTerm(error_func, noise_model, loss_func)\n",
    "    cost_terms.append(cost_term)\n",
    "# velocity measurements -> cost terms\n",
    "noise_model = StaticNoiseModel(w_iv_inv_noise)\n",
    "for t_l, w in w_iv_inv_meas:\n",
    "    intp_vel = traj.get_velocity_interpolator(Time(secs=t_l))\n",
    "    error_func = vspaceev.add(VSpaceStateVar(w, locked=True), vspaceev.neg(intp_vel))\n",
    "    cost_term = WeightedLeastSquareCostTerm(error_func, noise_model, loss_func)\n",
    "    cost_terms.append(cost_term)\n",
    "#\n",
    "opt_prob = OptimizationProblem()\n",
    "opt_prob.add_state_var(*[v for state_var in state_vars for v in state_var[1:]])\n",
    "opt_prob.add_cost_term(*traj.get_prior_cost_terms())\n",
    "opt_prob.add_cost_term(*cost_terms)\n",
    "\n",
    "solver = DoglegGaussNewtonSolver(opt_prob, verbose=False)\n",
    "solver.optimize()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# knot times\n",
    "knot_times = [x[0] for x in state_vars]\n",
    "knot_vels = np.array([traj.get_velocity_interpolator(Time(secs=t)).evaluate().flatten() for t in knot_times])\n",
    "knot_poses = [traj.get_pose_interpolator(Time(secs=t)).evaluate().inverse().matrix() for t in knot_times]\n",
    "knot_poses_vec = np.array([se3op.tran2vec(x).flatten() for x in knot_poses])\n",
    "\n",
    "# measurement values\n",
    "meas_pose_times = [x[0] for x in T_iv_meas]\n",
    "meas_poses = [x[1].matrix() for x in T_iv_meas]\n",
    "meas_poses_vec = np.array([se3op.tran2vec(x).flatten() for x in meas_poses])\n",
    "meas_vel_times = [x[0] for x in w_iv_inv_meas]\n",
    "meas_vels = np.array([x[1].flatten() for x in w_iv_inv_meas])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
