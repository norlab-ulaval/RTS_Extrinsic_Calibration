{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7891c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'GPy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgp_prediction_utils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mGPf\u001b[39;00m\n\u001b[1;32m     19\u001b[0m GPf \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mreload(GPf)\n",
      "File \u001b[0;32m~/Repo_git/code_publication_ICRA2023_MaximeVaidis/scripts/gp_prediction_utils.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaussian_process\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct, ConstantKernel)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mGPy\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#from pypointmatcher import pointmatcher as pm, pointmatchersupport as pms\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#PM = pm.PointMatcher\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#DP = PM.DataPoints\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'GPy'"
     ]
    }
   ],
   "source": [
    "import scipy.linalg\n",
    "import scipy.optimize\n",
    "import sys\n",
    "import numpy as np\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scripts.theodolite_function as tfu\n",
    "tfu = importlib.reload(tfu)\n",
    "from scipy.interpolate import splprep, splev\n",
    "from scipy import interpolate\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import scripts.theodolite_utils as ttfu\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import scripts.gp_prediction_utils as GPf\n",
    "GPf = importlib.reload(GPf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5ac7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_drop_outliers(file_name_path, param, results_arr):\n",
    "    file_name = file_name_path+str(param[0])+\"-\"+str(param[1])+\"-\"+str(param[2])+\"-\"+str(param[3])+\"-\"+str(param[4])+\"-\"+str(param[5])+\".txt\"\n",
    "    file = open(file_name,\"w+\")\n",
    "    file.write(str(results_arr[0]))\n",
    "    file.write(\" \")\n",
    "    file.write(str(results_arr[1]))\n",
    "    file.write(\" \")\n",
    "    file.write(str(results_arr[2]))\n",
    "    file.write(\" \")\n",
    "    file.write(str(results_arr[3]))\n",
    "    file.write(\" \")\n",
    "    file.write(str(results_arr[4]))\n",
    "    file.write(\" \")\n",
    "    file.write(str(results_arr[5]))\n",
    "    file.write(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "def read_results_drop_outliers(file_name):\n",
    "    data = []\n",
    "    with open(file_name, \"r\") as file:\n",
    "        for line in file:\n",
    "            item = line.strip().split(\" \")\n",
    "            data.append(item)\n",
    "    return data\n",
    "    \n",
    "def drop_points_filtering(file_name_path, param, repo_out):\n",
    "    number_points_input = []\n",
    "    number_points_out_outliers = []\n",
    "    number_points_out_filters_only = []\n",
    "    number_points_out_filters = []\n",
    "    number_points_out_outliers_end_with_outliers = []\n",
    "    number_points_out_outliers_end_without_ouliers = []\n",
    "    \n",
    "    for i, repo_out_name in zip(file_name_path,repo_out):\n",
    "        print(i)\n",
    "        \n",
    "        # Data filtered with outliers\n",
    "        t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = ttfu.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(i)\n",
    "        index_1_f = ttfu.thresold_raw_data(t1, d1, a1, e1, param[0], param[1]*3.1415926/180, param[2]*3.1415926/180, param[3])\n",
    "        index_2_f = ttfu.thresold_raw_data(t2, d2, a2, e2, param[0], param[1]*3.1415926/180, param[2]*3.1415926/180, param[3])\n",
    "        index_3_f = ttfu.thresold_raw_data(t3, d3, a3, e3, param[0], param[1]*3.1415926/180, param[2]*3.1415926/180, param[3])\n",
    "        t1 = t1[index_1_f]\n",
    "        t2 = t2[index_2_f]\n",
    "        t3 = t3[index_3_f]\n",
    "        tp1 = tp1[index_1_f].T\n",
    "        tp2 = tp2[index_2_f].T\n",
    "        tp3 = tp3[index_3_f].T\n",
    "\n",
    "        # Raw data\n",
    "        tr1, tr2, tr3, trp1, trp2, trp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = ttfu.read_rosbag_theodolite_without_tf_raw_data(i)\n",
    "\n",
    "        sum_input_points = len(tr1)+len(tr2)+len(tr3)\n",
    "        sum_outliers_points = len(t1)+len(t2)+len(t3)\n",
    "        \n",
    "        # data filtered in pipeline\n",
    "        list_interval, list_time = tfu.split_time_interval_all_data(t1, t2, t3, param[3])\n",
    "        list_trajectories_split = tfu.merge_interval(list_interval, list_time, t1, t2, t3, param[3])\n",
    "        \n",
    "        sum_filters_points = 0\n",
    "        sum_filters_points_with_outliers = 0\n",
    "        \n",
    "        for j in tqdm(list_trajectories_split):\n",
    "            index_1 = np.array([j[0,0],j[1,0]])\n",
    "            index_2 = np.array([j[0,1],j[1,1]])\n",
    "            index_3 = np.array([j[0,2],j[1,2]])\n",
    "            \n",
    "            sum_filters_points = sum_filters_points + len(t1[index_1[0]:index_1[1]]) + len(t2[index_2[0]:index_2[1]]) + len(t3[index_3[0]:index_3[1]])\n",
    "            \n",
    "            index_1 = GPf.delta_t_function(index_1,t1,param[4])\n",
    "            index_2 = GPf.delta_t_function(index_2,t2,param[4])\n",
    "            index_3 = GPf.delta_t_function(index_3,t3,param[4])\n",
    "                \n",
    "            begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])\n",
    "            end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])\n",
    "\n",
    "            if(abs(end-begin)>param[5] and begin<end):\n",
    "                sum_filters_points_with_outliers = sum_filters_points_with_outliers + len(t1[index_1[0]:index_1[1]]) + len(t2[index_2[0]:index_2[1]]) + len(t3[index_3[0]:index_3[1]]) \n",
    "            \n",
    "        # Raw data in pipeline\n",
    "        list_interval, list_time = tfu.split_time_interval_all_data(tr1, tr2, tr3, param[3])\n",
    "        list_trajectories_split = tfu.merge_interval(list_interval, list_time, tr1, tr2, tr3, param[3])\n",
    "        \n",
    "        sum_filters_points_only = 0\n",
    "        sum_filters_points_without_outliers = 0\n",
    "        \n",
    "        for j in tqdm(list_trajectories_split):\n",
    "            index_1 = np.array([j[0,0],j[1,0]])\n",
    "            index_2 = np.array([j[0,1],j[1,1]])\n",
    "            index_3 = np.array([j[0,2],j[1,2]])\n",
    "            \n",
    "            sum_filters_points_only = sum_filters_points_only + len(tr1[index_1[0]:index_1[1]]) + len(tr2[index_2[0]:index_2[1]]) + len(tr3[index_3[0]:index_3[1]])\n",
    "\n",
    "            index_1 = GPf.delta_t_function(index_1,tr1,param[4])\n",
    "            index_2 = GPf.delta_t_function(index_2,tr2,param[4])\n",
    "            index_3 = GPf.delta_t_function(index_3,tr3,param[4])\n",
    "                \n",
    "            begin = np.max([tr1[index_1[0]], tr2[index_2[0]], tr3[index_3[0]]])\n",
    "            end = np.min([tr1[index_1[1]], tr2[index_2[1]], tr3[index_3[1]]])\n",
    "\n",
    "            if(abs(end-begin)>param[5] and begin<end):\n",
    "                sum_filters_points_without_outliers = sum_filters_points_without_outliers + len(tr1[index_1[0]:index_1[1]]) + len(tr2[index_2[0]:index_2[1]]) + len(tr3[index_3[0]:index_3[1]]) \n",
    "\n",
    "        number_points_input.append(sum_input_points)\n",
    "        number_points_out_outliers.append(sum_outliers_points)\n",
    "        number_points_out_filters.append(sum_filters_points)\n",
    "        number_points_out_filters_only.append(sum_filters_points_only)\n",
    "        number_points_out_outliers_end_with_outliers.append(sum_filters_points_with_outliers)\n",
    "        number_points_out_outliers_end_without_ouliers.append(sum_filters_points_without_outliers)\n",
    "        \n",
    "        results_arr = np.array([sum_input_points, sum_outliers_points, sum_filters_points, sum_filters_points_only, sum_filters_points_with_outliers, sum_filters_points_without_outliers])\n",
    "        save_results_drop_outliers(repo_out_name, param, results_arr)\n",
    "\n",
    "    print(\"Results done !\")\n",
    "    \n",
    "    return number_points_input, number_points_out_outliers, number_points_out_filters, number_points_out_filters_only, number_points_out_outliers_end_with_outliers, number_points_out_outliers_end_without_ouliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ee44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = [\"/home/norlab/Data/IROS_2022/20220224_TS/2022-02-24-15-34-38.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220307_TS/2022-03-07-19-20-06.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220312_TS/2022-03-12-09-45-12.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220314_TS/2022-03-14-10-47-49.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220316_TS/2022-03-16-19-02-42.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220331_TS/2022-03-31-10-22-52.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220331_TS/2022-03-31-11-20-05.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220427_TS/2022-04-27-12-12-10_filered.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220505_TS/empty1_2022-05-05-19-14-33.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220505_TS/cones1_2022-05-05-19-25-54.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220513_TS/2022-05-13-10-30-37_filtered.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220513_TS/2022-05-13-11-01-56.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220513_TS/2022-05-13-11-24-28.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220513_TS/2022-05-13-21-49-12_filtered.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220513_TS/2022-05-13-22-35-30.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220513_TS/2022-05-13-22-51-40.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220523_TS/cones_filtered_2022-05-23-19-31-32.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220523_TS/constrained_2022-05-23-18-56-16.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220523_TS/empty_filtered_2022-05-23-19-18-35.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220523_TS/other_tunnel_2022-05-23-19-39-40.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220525_TS/2022-05-25-11-07-40.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220525_TS/2022-05-25-13-32-32.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220622_TS/2022-06-22-17-48-25.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220622_TS/2022-06-22-18-11-00.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220630_TS/2022-06-30-10-32-21.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220630_TS/2022-06-30-10-57-07.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220711_TS/2022-07-11-15-36-04.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220711_TS/2022-07-11-15-50-00.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220715_TS/2022-07-15-11-50-15.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220715_TS/2022-07-15-11-53-12.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220715_TS/2022-07-15-11-58-58.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220715_TS/2022-07-15-14-42-27.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220717_TS/constrained_2022-07-17-20-10-31.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220717_TS/constrained_2022-07-17-20-11-10.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220717_TS/cones_2022-07-17-20-38-29.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220717_TS/empty_2022-07-17-21-03-14.bag\",\n",
    "        \"/home/norlab/Data/IROS_2022/20220717_TS/calibration_2022-07-17-21-27-28.bag\"\n",
    "       ]\n",
    "\n",
    "repo_out = [\n",
    "    './data/drop_outliers/20220224/',\n",
    "    './data/drop_outliers/20220307/',\n",
    "    './data/drop_outliers/20220312/',\n",
    "    './data/drop_outliers/20220314/',\n",
    "    './data/drop_outliers/20220316/',\n",
    "    './data/drop_outliers/20220331-1/',\n",
    "    './data/drop_outliers/20220331-2/',\n",
    "    './data/drop_outliers/20220427/',\n",
    "    './data/drop_outliers/20220505_empty/',\n",
    "    './data/drop_outliers/20220505_cones/',\n",
    "    './data/drop_outliers/20220513/01/',\n",
    "    './data/drop_outliers/20220513/02/',\n",
    "    './data/drop_outliers/20220513/03/',\n",
    "    './data/drop_outliers/20220513/04/',\n",
    "    './data/drop_outliers/20220513/05/',\n",
    "    './data/drop_outliers/20220513/06/',\n",
    "    './data/drop_outliers/20220523_cones/',\n",
    "    './data/drop_outliers/20220523_constrained/',\n",
    "    './data/drop_outliers/20220523_empty/',\n",
    "    './data/drop_outliers/20220523_other_tunnel/',\n",
    "    './data/drop_outliers/20220525/01/',\n",
    "    './data/drop_outliers/20220525/02/',\n",
    "    './data/drop_outliers/20220622-1/',\n",
    "    './data/drop_outliers/20220622-2/',\n",
    "    './data/drop_outliers/20220630-1/',\n",
    "    './data/drop_outliers/20220630-2/',\n",
    "    './data/drop_outliers/20220711/01/',\n",
    "    './data/drop_outliers/20220711/02/',\n",
    "    './data/drop_outliers/20220715/01/',\n",
    "    './data/drop_outliers/20220715/02/',\n",
    "    './data/drop_outliers/20220715/03/',\n",
    "    './data/drop_outliers/20220715/04/',\n",
    "    './data/drop_outliers/20220717/01/',\n",
    "    './data/drop_outliers/20220717/02/',\n",
    "    './data/drop_outliers/20220717/03/',\n",
    "    './data/drop_outliers/20220717/04/',\n",
    "    './data/drop_outliers/20220717/05/'\n",
    "]\n",
    "\n",
    "# Outlier range\n",
    "#param = [np.array([0.5, 10, 10, 1, 0, 6]),\n",
    "#         np.array([1, 10, 10, 1, 0, 6]),\n",
    "#         np.array([1.5, 10, 10, 1, 0, 6]),\n",
    "#         np.array([2, 10, 10, 1, 0, 6]),\n",
    "#         np.array([2.5, 10, 10, 1, 0, 6]),\n",
    "#         np.array([3, 10, 10, 1, 0, 6]),\n",
    "#        ]\n",
    "\n",
    "# Outlier azimuth angle\n",
    "#param = [np.array([10, 0.5, 10, 1, 0, 6]),\n",
    "#         np.array([10, 1, 10, 1, 0, 6]),\n",
    "#         np.array([10, 1.5, 10, 1, 0, 6]),\n",
    "#         np.array([10, 2, 10, 1, 0, 6]),\n",
    "#         np.array([10, 2.5, 10, 1, 0, 6]),\n",
    "#         np.array([10, 3, 10, 1, 0, 6]),\n",
    "#        ]\n",
    "\n",
    "# Outlier elevation angle\n",
    "#param = [np.array([10, 10, 0.5, 1, 0, 6]),\n",
    "#         np.array([10, 10, 1, 1, 0, 6]),\n",
    "#         np.array([10, 10, 1.5, 1, 0, 6]),\n",
    "#         np.array([10, 10, 2, 1, 0, 6]),\n",
    "#         np.array([10, 10, 2.5, 1, 0, 6]),\n",
    "#         np.array([10, 10, 3, 1, 0, 6]),\n",
    "#        ]\n",
    "\n",
    "# split time interval \n",
    "#param = [np.array([2, 1, 1, 0.5, 0, 6]),\n",
    "#         np.array([2, 1, 1, 0.75, 0, 6]),\n",
    "#         np.array([2, 1, 1, 1, 0, 6]),\n",
    "#         np.array([2, 1, 1, 1.25, 0, 6]),\n",
    "#         np.array([2, 1, 1, 1.5, 0, 6]),\n",
    "#         np.array([2, 1, 1, 1.75, 0, 6]),\n",
    "#         np.array([2, 1, 1, 2, 0, 6]),\n",
    "#         np.array([2, 1, 1, 2.25, 0, 6]),\n",
    "#         np.array([2, 1, 1, 2.5, 0, 6])\n",
    "#        ]\n",
    "\n",
    "# delta_t \n",
    "param = [np.array([2, 1, 1, 1, 0, 6]),\n",
    "         np.array([2, 1, 1, 1, 0.25, 6]),\n",
    "         np.array([2, 1, 1, 1, 0.5, 6]),\n",
    "         np.array([2, 1, 1, 1, 0.75, 6]),\n",
    "         np.array([2, 1, 1, 1, 1, 6]),\n",
    "         np.array([2, 1, 1, 1, 1.25, 6]),\n",
    "         np.array([2, 1, 1, 1, 1.5, 6]),\n",
    "         np.array([2, 1, 1, 1, 1.75, 6]),\n",
    "         np.array([2, 1, 1, 1, 2, 6])\n",
    "        ]\n",
    "\n",
    "# split time interval \n",
    "#param = [np.array([2, 1, 1, 1, 0, 2]),\n",
    "#         np.array([2, 1, 1, 1, 0, 4]),\n",
    "#         np.array([2, 1, 1, 1, 0, 6]),\n",
    "#         np.array([2, 1, 1, 1, 0, 8]),\n",
    "#         np.array([2, 1, 1, 1, 0, 10]),\n",
    "#         np.array([2, 1, 1, 1, 0, 12])\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c8011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_points_input = []\n",
    "mean_point_out_outlier = []\n",
    "mean_point_out_filter = []\n",
    "mean_point_out_filter_only = []\n",
    "mean_points_out_outliers_end_with_outliers = []\n",
    "mean_points_out_outliers_end_without_outliers = []\n",
    "for i in param:\n",
    "    print(\"**********************************************\")\n",
    "    print(\"**********************************************\")\n",
    "    print(i)\n",
    "    number_points_input, number_points_out_outliers, number_points_out_filters, number_points_out_filters_only, number_points_out_outliers_end_with_outliers, number_points_out_outliers_end_without_ouliers = drop_points_filtering(file, i, repo_out)\n",
    "    mean_points_input.append(np.sum(number_points_input))\n",
    "    mean_point_out_outlier.append(np.sum(number_points_out_outliers))\n",
    "    mean_point_out_filter.append(np.sum(number_points_out_filters))\n",
    "    mean_point_out_filter_only.append(np.sum(number_points_out_filters_only))\n",
    "    mean_points_out_outliers_end_with_outliers.append(np.sum(number_points_out_outliers_end_with_outliers))\n",
    "    mean_points_out_outliers_end_without_outliers.append(np.sum(number_points_out_outliers_end_without_ouliers))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param[0])\n",
    "file_name = repo_out[0]+str(param[0][0])+\"-\"+str(param[0][1])+\"-\"+str(param[0][2])+\"-\"+str(param[0][3])+\"-\"+str(param[0][4])+\"-\"+str(param[0][5])+\".txt\"\n",
    "results = read_results_drop_outliers(file_name)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385666a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage points removed by outliers/filters\n",
    "\n",
    "percentage_out_outliers = []\n",
    "percentage_out_filters = []\n",
    "percentage_out_total_outliers_filters = []\n",
    "percentage_out_end_outliers_only = []\n",
    "percentage_out_total = []\n",
    "for i,j,k,l,m,n in zip(mean_points_input, mean_point_out_outlier, mean_point_out_filter, mean_point_out_filter_only, mean_points_out_outliers_end_with_outliers, mean_points_out_outliers_end_without_outliers):\n",
    "    percentage_outliers_only = (i-j)/i*100\n",
    "    percentage_filters_only = (i-l)/i*100\n",
    "    percentage_total_outliers_filters = (i-k)/i*100\n",
    "    percentage_end_outliers_only = abs(l-n)/i*100\n",
    "    percentage_total = (i-m)/i*100\n",
    "    \n",
    "    percentage_out_outliers.append(percentage_outliers_only)\n",
    "    percentage_out_filters.append(percentage_filters_only)\n",
    "    percentage_out_total_outliers_filters.append(percentage_total_outliers_filters)\n",
    "    percentage_out_end_outliers_only.append(percentage_end_outliers_only)\n",
    "    percentage_out_total.append(percentage_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "y_limit = 360000\n",
    "#arr = [\"0.5\", \"1\", \"1.5\", \"2\", \"2.5\", \"3\"]  #30min for distance outliers generation, azimuth, elevation\n",
    "#arr = [\"0\", \"0.25\",\"0.5\",\"0.75\", \"1\", \"1.25\",\"1.5\",\"1.75\", \"2\"]  #50min for delta_t outliers generation\n",
    "#arr = [\"0.5\", \"0.75\",\"1\",\"1.25\", \"1.5\", \"1.75\",\"2\",\"2.25\", \"2.5\"]  #50min for time split interval generation\n",
    "arr = [\"2\", \"4\",\"6\",\"8\", \"10\", \"12\"]  #40min for length interval generation\n",
    "\n",
    "#arr = [\"0.5\",\"1\",\"1.5\",\"2\"]\n",
    "#arr = [\"0.5\",\"1\",\"1.5\",\"2\"]\n",
    "\n",
    "fig = plt.figure(figsize =(8,8))\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(mean_points_input, color='r', label=\"total points\")\n",
    "ax.plot(mean_point_out_outlier, color='b', label=\"points outlier\")\n",
    "ax.plot(mean_point_out_filter, color='g', label=\"points filter\")\n",
    "ax.plot(mean_points_out_outliers_end_with_outliers, color='yellow', label=\"points end outliers\")\n",
    "ax.set_ylabel(\"Number points\")\n",
    "ax.set_ylim([0,y_limit])\n",
    "ax.legend(mode = \"expand\", ncol = 4)\n",
    "#plt.xticks([0, 1, 2, 3, 4, 5], arr)\n",
    "#ax.set_xlabel(\"Outlier distance [m.s^-1]\")\n",
    "#ax.set_xlabel(\"Outlier azimuth [deg/s]\")\n",
    "#ax.set_xlabel(\"Outlier elevation [deg/s]\")\n",
    "#plt.xticks([0, 1, 2, 3, 4, 5,6,7], arr)\n",
    "#ax.set_xlabel(\"Outlier delta_t [s]\")\n",
    "#ax.set_xlabel(\"Time split [s]\")\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], arr)\n",
    "ax.set_xlabel(\"Length interval [s]\")\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(percentage_out_outliers, color='b', label=\"outlier\")\n",
    "ax2.plot(percentage_out_filters, color='g', label=\"filtered\")\n",
    "ax2.plot(percentage_out_end_outliers_only, color='r', label=\"end outliers\")\n",
    "ax2.plot(percentage_out_total, color='black', label=\"total\")\n",
    "ax2.legend(mode = \"expand\", ncol = 4)\n",
    "ax2.set_ylim([0,100])\n",
    "ax2.set_ylabel(\"Percentage removed [%]\")\n",
    "#plt.xticks([0, 1, 2, 3, 4, 5], arr)\n",
    "#ax2.set_xlabel(\"Outlier distance [m.s^-1]\")\n",
    "#ax2.set_xlabel(\"Outlier azimuth [deg/s]\")\n",
    "#ax2.set_xlabel(\"Outlier elevation [deg/s]\")\n",
    "#plt.xticks([0, 1, 2, 3, 4, 5,6,7], arr)\n",
    "#ax2.set_xlabel(\"Outlier delta_t [s]\")\n",
    "#ax2.set_xlabel(\"Time split [s]\")\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], arr)\n",
    "ax2.set_xlabel(\"Length interval [s]\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig(\"./figs/number_points_removed_distance-f-n-10-10-1-0-6.jpg\")\n",
    "#fig.savefig(\"./figs/number_points_removed_azimuth-f-10-n-10-1-0-6.jpg\")\n",
    "#fig.savefig(\"./figs/number_points_removed_elevation-f-10-10-n-1-0-6.jpg\")\n",
    "#fig.savefig(\"./figs/number_points_removed_delta_t-f-2-1-1-1-n-6.jpg\")\n",
    "#fig.savefig(\"./figs/number_points_removed_time_split-f-2-1-1-n-0-6.jpg\")\n",
    "#fig.savefig(\"./figs/number_points_removed_length_interval-f-2-1-1-1-0-n.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c8ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
