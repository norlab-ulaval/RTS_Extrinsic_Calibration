{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing pipeline\n",
    "\n",
    "Notebook used to compute the pre-processing pipeline on the raw data coming from one deployment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83134f9a-9db2-4600-a9e2-cb67d376842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import importlib\n",
    "import scripts.theodolite_utils as theodo_u\n",
    "import scripts.theodolite_function as theodo_f\n",
    "import scripts.prediction_utils as prediction_u\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from stheno.torch import B\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selection of datasets and pre-processing pipeline parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selection of files and parameters\n",
    "\n",
    "# Path of the rosbags\n",
    "file = [\n",
    "        \"/home/maxime/data/ICRA_2023/Vaidis2022_dataset/20220224/20220224_inter_prism.bag\"\n",
    "       ]\n",
    "\n",
    "# Path of output\n",
    "output = [\n",
    "        \"../data/20220224/\"\n",
    "]\n",
    "\n",
    "# Parameters to select:\n",
    "# 1. Apply filtering or not (Module 1)\n",
    "# 2-3-4. Parameters tau_r, tau_a, tau_e (Module 1)\n",
    "# 5. Parameter tau_s (Module 2)\n",
    "# 6. Parameter tau_l (Module 3)\n",
    "# 7. Parameter to cut edge of sub-intervals (former parameter with low impact)\n",
    "parameters = [\n",
    "    [1,2,1,1,1,6,0],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e2fb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "theodo_f = importlib.reload(theodo_f)\n",
    "prediction_u = importlib.reload(prediction_u)\n",
    "\n",
    "for param in parameters:\n",
    "    print(param)\n",
    "\n",
    "    if(param[0]==0):\n",
    "        filtering = False\n",
    "    if(param[0]==1):\n",
    "        filtering = True\n",
    "    thresold_d = param[1]                # tau_r [m/s]\n",
    "    thresold_a = param[2]                # tau_a [deg/s]\n",
    "    thresold_e = param[3]                # tau_e [deg/s]\n",
    "    limit_time_interval = param[4]       # tau_s [s]\n",
    "\n",
    "    B.epsilon = 1e-8\n",
    "    Mode = \"SGP\"       # Interpolation choice: 1. L -> Linear interpolation, 2. SGP -> Gaussian Process with Stheno library\n",
    "    limit_search = limit_time_interval\n",
    "    size_interval = param[5]         # tau_l [s]\n",
    "    delta_t = param[6]               # Value to remove points near edge of time intervals [s]\n",
    "    save = False\n",
    "\n",
    "    # GP parameters\n",
    "    verbose=False\n",
    "    Number_restart = 100        # Number of restart for the GP\n",
    "    noise_GP = 0                # Noise of GP\n",
    "    variance_GP = 1             # Variance of GP\n",
    "    lengthscale_GP = 1          # Lengthscale of GP\n",
    "\n",
    "    save_index_1 = []\n",
    "    save_index_2 = []\n",
    "    save_index_3 = []\n",
    "\n",
    "    for fname, opath in zip(file,output): \n",
    "        if(not filtering):\n",
    "            path = opath + \"raw_prediction/\"\n",
    "        else:\n",
    "            path = opath + \"filtered_prediction/\"\n",
    "\n",
    "        if(filtering):\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data_pre_filtered(fname)\n",
    "            index_1_f = theodo_u.thresold_raw_data(t1, d1, a1, e1, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_2_f = theodo_u.thresold_raw_data(t2, d2, a2, e2, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            index_3_f = theodo_u.thresold_raw_data(t3, d3, a3, e3, thresold_d, thresold_a*3.1415926/180, thresold_e*3.1415926/180, limit_time_interval)\n",
    "            t1 = t1[index_1_f]\n",
    "            t2 = t2[index_2_f]\n",
    "            t3 = t3[index_3_f]\n",
    "            tp1 = tp1[index_1_f].T\n",
    "            tp2 = tp2[index_2_f].T\n",
    "            tp3 = tp3[index_3_f].T\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "        else:\n",
    "            t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data(fname)\n",
    "            print(len(t1),len(t2),len(t3))\n",
    "\n",
    "        time_origin = np.min([t1[0],t2[0],t3[0]])\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        t1 = t1 - np.ones_like(t1)*time_origin\n",
    "        t2 = t2 - np.ones_like(t2)*time_origin\n",
    "        t3 = t3 - np.ones_like(t3)*time_origin\n",
    "\n",
    "        list_interval, list_time = theodo_f.split_time_interval_all_data(t1, t2, t3, limit_time_interval)\n",
    "        list_trajectories_split = theodo_f.merge_interval(list_interval, list_time, t1, t2, t3, limit_search)\n",
    "\n",
    "        Prediction_1 = []\n",
    "        Prediction_2 = []\n",
    "        Prediction_3 = []\n",
    "        T_prediction = []\n",
    "\n",
    "        for i in tqdm(list_trajectories_split):\n",
    "\n",
    "            index_1 = np.array([i[0,0],i[1,0]])\n",
    "            index_2 = np.array([i[0,1],i[1,1]])\n",
    "            index_3 = np.array([i[0,2],i[1,2]])\n",
    "\n",
    "            save_index_1.append(index_1)\n",
    "            save_index_2.append(index_2)\n",
    "            save_index_3.append(index_3)\n",
    "\n",
    "            if(filtering==True):\n",
    "                index_1 = prediction_u.delta_t_function(index_1,t1,delta_t)\n",
    "                index_2 = prediction_u.delta_t_function(index_2,t2,delta_t)\n",
    "                index_3 = prediction_u.delta_t_function(index_3,t3,delta_t)\n",
    "\n",
    "            begin = np.max([t1[index_1[0]], t2[index_2[0]], t3[index_3[0]]])\n",
    "            end = np.min([t1[index_1[1]], t2[index_2[1]], t3[index_3[1]]])\n",
    "\n",
    "            if(abs(end-begin)>size_interval and begin<end):\n",
    "\n",
    "                rate = 10  #Hz\n",
    "                T_prediction_init = torch.from_numpy(np.arange(begin, end, 1/rate))\n",
    "\n",
    "                # Test done for Multiple Gaussian Process Output\n",
    "                if(Mode == \"MGPO\" or Mode == \"All\"):\n",
    "                    T_MGPO, S_MGPO = prediction_u.data_training_MGPO(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    print(\"Training\")\n",
    "                    m = prediction_u.training_MGPO(Number_restart, verbose, T_MGPO, S_MGPO)\n",
    "                    print(\"Prediction\")\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                        P1_MGPO, P2_MGPO, P3_MGPO = prediction_u.unit_prediction_MGPO(i, m)\n",
    "                        Prediction_1.append(P1_MGPO)\n",
    "                        Prediction_2.append(P2_MGPO)\n",
    "                        Prediction_3.append(P3_MGPO)\n",
    "\n",
    "                # Gaussian process with GPy library\n",
    "                if(Mode == \"GP\" or Mode == \"All\"):\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = prediction_u.data_training_GP(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    print(\"Training\")\n",
    "                    mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = prediction_u.training_GP(Number_restart, verbose, T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3)\n",
    "                    print(\"Prediction\")\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                        P1_GP, P2_GP, P3_GP = prediction_u.unit_prediction_GP(i, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                        Prediction_1.append(P1_GP)\n",
    "                        Prediction_2.append(P2_GP)\n",
    "                        Prediction_3.append(P3_GP)\n",
    "\n",
    "                # Linear interpolation\n",
    "                if(Mode == \"L\" or Mode == \"All\"):\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = prediction_u.data_training_L(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    print(\"Prediction\")\n",
    "                    mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3 = prediction_u.linear_interpolation(T1, X1, Y1, Z1, T2, X2, Y2, Z2,T3, X3, Y3, Z3)\n",
    "\n",
    "                    for i in T_prediction_init.numpy():\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                        P1_GP, P2_GP, P3_GP = prediction_u.linear_prediction(i, time_origin, mx1, my1, mz1, mx2, my2, mz2, mx3, my3, mz3)\n",
    "                        Prediction_1.append(P1_GP)\n",
    "                        Prediction_2.append(P2_GP)\n",
    "                        Prediction_3.append(P3_GP)\n",
    "\n",
    "                # Gaussian process with Stheno library\n",
    "                if(Mode==\"SGP\"):\n",
    "                    prediction_value = T_prediction_init.numpy()\n",
    "                    # Prepare data for training\n",
    "                    T1, X1, Y1, Z1, T2, X2, Y2, Z2, T3, X3, Y3, Z3 = prediction_u.data_training_GP_stheno(t1, t2, t3, tp1, tp2, tp3, index_1, index_2, index_3)\n",
    "                    # Training for each axis\n",
    "                    m_X1, v_X1 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=X1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Y1, v_Y1 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=Y1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Z1, v_Z1 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T1, y_obs=Z1, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_X2, v_X2 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=X2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Y2, v_Y2 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=Y2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Z2, v_Z2 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T2, y_obs=Z2, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_X3, v_X3 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=X3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Y3, v_Y3 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=Y3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "                    m_Z3, v_Z3 = prediction_u.GP_function_stheno(x=prediction_value, x_obs=T3, y_obs=Z3, variance=variance_GP, lengthscale=lengthscale_GP, noise_init=noise_GP, optimization_nb=Number_restart)\n",
    "\n",
    "                    # Save prediction at time i\n",
    "                    for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X1, m_Y1, m_Z1, v_X1, v_Y1, v_Z1):\n",
    "                        Prediction_1.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "                        T_prediction.append(i+time_origin)\n",
    "                    for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X2, m_Y2, m_Z2, v_X2, v_Y2, v_Z2):\n",
    "                        Prediction_2.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "                    for i,mx,my,mz,vx,vy,vz in zip(T_prediction_init.numpy(), m_X3, m_Y3, m_Z3, v_X3, v_Y3, v_Z3):\n",
    "                        Prediction_3.append(np.array([i+time_origin, mx ,my, mz, vx, vy, vz]))\n",
    "\n",
    "        stop_time = time.time()\n",
    "        print(stop_time - start_time)\n",
    "\n",
    "        print(\"Interpolation finished !\")\n",
    "\n",
    "        if save:\n",
    "            if(Mode == \"MGPO\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-MGPO-\"+str(Number_restart)\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-MGPO-\"+str(Number_restart)\n",
    "\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path+trajectoire+ \"_1.csv\")\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path+trajectoire+ \"_2.csv\")\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path+trajectoire+ \"_3.csv\")\n",
    "            if(Mode == \"GP\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-GP-\"+str(Number_restart)\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-GP-\"+str(Number_restart)\n",
    "\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path+trajectoire+ \"_1.csv\")\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path+trajectoire+ \"_2.csv\")\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path+trajectoire+ \"_3.csv\")\n",
    "            if(Mode == \"SGP\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-SGP-\"+str(Number_restart)\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-SGP-\"+str(Number_restart)\n",
    "\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_1, path+trajectoire+ \"_1.csv\")\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_2, path+trajectoire+ \"_2.csv\")\n",
    "                theodo_u.Convert_data_prediction_to_csv(T_prediction, Prediction_3, path+trajectoire+ \"_3.csv\")\n",
    "            if(Mode == \"L\" or Mode == \"All\"):\n",
    "                if(filtering):\n",
    "                    trajectoire = \"f-\"+str(thresold_d)+\"-\"+str(thresold_a)+\"-\"+str(thresold_e)+\"-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-L\"\n",
    "                else:\n",
    "                    trajectoire = \"nf-\"+str(limit_time_interval)+\"-\"+str(size_interval)+\"-\"+str(delta_t)+\"-L\"\n",
    "\n",
    "                if save:\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_1, path+trajectoire+ \"_1.csv\")\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_2, path+trajectoire+ \"_2.csv\")\n",
    "                    theodo_u.Convert_raw_data_point_to_csv(T_prediction, Prediction_3, path+trajectoire+ \"_3.csv\")\n",
    "\n",
    "        print(\"Saved !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Display results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b510b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "theodo_u = importlib.reload(theodo_u)\n",
    "\n",
    "k = '../data/20220224/'\n",
    "path_type = 'filtered_prediction/'\n",
    "#path_file_type = 'nf-1-6-1-L_'\n",
    "path_file_type = 'f-2-1-1-1-6-0-L_'\n",
    "\n",
    "trimble_1 = theodo_u.read_prediction_data_resection_csv_file(k+path_type+path_file_type+\"1.csv\")\n",
    "t1, t2, t3, tp1, tp2, tp3, d1, d2, d3, a1, a2, a3, e1, e2, e3 = theodo_u.read_rosbag_theodolite_without_tf_raw_data(\"/home/maxime/data/ICRA_2023/Vaidis2022_dataset/20220224/20220224_inter_prism.bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "save_index_1_arr = np.array(save_index_1)\n",
    "i = save_index_1_arr[0]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(t1,tp1[0,:],s =1)                                               # Raw data from rosbag\n",
    "plt.scatter(t1[i[0]:i[1]],tp1[0,i[0]:i[1]], linewidth=5, color= 'black')      # Data given as input for the interpolation\n",
    "plt.scatter(trimble_1[:,0],trimble_1[:,1], linewidth=2, color= 'red')       # Interpolated points\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Axis chosen [m]\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544ca35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
